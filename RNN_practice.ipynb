{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "載入資料"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import string\n",
    "from collections import defaultdict\n",
    "import logging\n",
    "from gensim.models import word2vec\n",
    "\n",
    "from keras.models import Model, Sequential, load_model\n",
    "from keras.layers import Dense, Activation\n",
    "from keras.layers.recurrent import LSTM\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wugu504/venv/lib/python3.6/site-packages/ipykernel_launcher.py:3: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "path = \"./ml-2017fall-hw4/\"\n",
    "\n",
    "train = pd.read_csv(path + \"training_label.txt\", sep=\"\\+\\+\\+\\$\\+\\+\\+\", header=None, names=[\"target\", \"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>are wtf ... awww thanks !</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>leavingg to wait for kaysie to arrive myspaci...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>i wish i could go and see duffy when she come...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>i know eep ! i can ' t wait for one more day ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>so scared and feeling sick . fuck ! hope some...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   target                                               text\n",
       "0       1                          are wtf ... awww thanks !\n",
       "1       1   leavingg to wait for kaysie to arrive myspaci...\n",
       "2       0   i wish i could go and see duffy when she come...\n",
       "3       1   i know eep ! i can ' t wait for one more day ...\n",
       "4       0   so scared and feeling sick . fuck ! hope some..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mkhang mlbo . dami niang followers ee . di q r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>don ' t you hate it when you hang on to a seem...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ok so never went to the movies because friend ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>can ' t wait to see diversity ' s performance !</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>i love britney spears haha joey this is what u...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text\n",
       "0  mkhang mlbo . dami niang followers ee . di q r...\n",
       "1  don ' t you hate it when you hang on to a seem...\n",
       "2  ok so never went to the movies because friend ...\n",
       "3    can ' t wait to see diversity ' s performance !\n",
       "4  i love britney spears haha joey this is what u..."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nolabel = pd.read_csv(path + \"training_nolabel.txt\", header=None, index_col=False, names=[\"text\"])\n",
    "nolabel.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wugu504/venv/lib/python3.6/site-packages/ipykernel_launcher.py:2: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>my dog ate our dinner . no , seriously ... he ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>omg last day sooon n of primary noooooo x im g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>stupid boys .. they ' re so .. stupid !</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>hi ! do u know if the nurburgring is open for ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>having lunch in the office , and thinking of h...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                               text\n",
       "0   0  my dog ate our dinner . no , seriously ... he ...\n",
       "1   1  omg last day sooon n of primary noooooo x im g...\n",
       "2   2            stupid boys .. they ' re so .. stupid !\n",
       "3   3  hi ! do u know if the nurburgring is open for ...\n",
       "4   4  having lunch in the office , and thinking of h..."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = \"./ml-2017fall-hw4/\"\n",
    "test = pd.read_csv(path + \"testing_data.txt\", sep=\"^([^,]+),\", header=0, index_col=False).iloc[:,1:]\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' are wtf ... awww thanks !',\n",
       " ' leavingg to wait for kaysie to arrive myspacin itt for now ilmmthek .!',\n",
       " ' i wish i could go and see duffy when she comes to mamaia romania .',\n",
       " \" i know eep ! i can ' t wait for one more day ....\",\n",
       " ' so scared and feeling sick . fuck ! hope someone at hr help ... wish it would be wendita or karen .']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordlist = list(train[\"text\"]) + list(nolabel[\"text\"]) + list(test[\"text\"])\n",
    "wordlist[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "全部轉為小寫"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' are wtf ... awww thanks !',\n",
       " ' leavingg to wait for kaysie to arrive myspacin itt for now ilmmthek .!',\n",
       " ' i wish i could go and see duffy when she comes to mamaia romania .',\n",
       " \" i know eep ! i can ' t wait for one more day ....\",\n",
       " ' so scared and feeling sick . fuck ! hope someone at hr help ... wish it would be wendita or karen .']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordlist = [str(x).lower() for x in wordlist]\n",
    "wordlist[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "移除數字"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' are wtf ... awww thanks !',\n",
       " ' leavingg to wait for kaysie to arrive myspacin itt for now ilmmthek .!',\n",
       " ' i wish i could go and see duffy when she comes to mamaia romania .',\n",
       " \" i know eep ! i can ' t wait for one more day ....\",\n",
       " ' so scared and feeling sick . fuck ! hope someone at hr help ... wish it would be wendita or karen .']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordlist = [re.sub(r\"\\d+\", \"\", x) for x in wordlist]\n",
    "wordlist[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "移除標點符號"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' are wtf  awww thanks ',\n",
       " ' leavingg to wait for kaysie to arrive myspacin itt for now ilmmthek ',\n",
       " ' i wish i could go and see duffy when she comes to mamaia romania ',\n",
       " ' i know eep  i can  t wait for one more day ',\n",
       " ' so scared and feeling sick  fuck  hope someone at hr help  wish it would be wendita or karen ']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordlist = [x.translate(str.maketrans(\"\", \"\", string.punctuation)) for x in wordlist]\n",
    "wordlist[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "移除前後的空格"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['are wtf  awww thanks',\n",
       " 'leavingg to wait for kaysie to arrive myspacin itt for now ilmmthek',\n",
       " 'i wish i could go and see duffy when she comes to mamaia romania',\n",
       " 'i know eep  i can  t wait for one more day',\n",
       " 'so scared and feeling sick  fuck  hope someone at hr help  wish it would be wendita or karen']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordlist = [x.strip() for x in wordlist]\n",
    "wordlist[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "將句子中的字詞拆解"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['are', 'wtf', 'awww', 'thanks'],\n",
       " ['leavingg',\n",
       "  'to',\n",
       "  'wait',\n",
       "  'for',\n",
       "  'kaysie',\n",
       "  'to',\n",
       "  'arrive',\n",
       "  'myspacin',\n",
       "  'itt',\n",
       "  'for',\n",
       "  'now',\n",
       "  'ilmmthek'],\n",
       " ['i',\n",
       "  'wish',\n",
       "  'i',\n",
       "  'could',\n",
       "  'go',\n",
       "  'and',\n",
       "  'see',\n",
       "  'duffy',\n",
       "  'when',\n",
       "  'she',\n",
       "  'comes',\n",
       "  'to',\n",
       "  'mamaia',\n",
       "  'romania'],\n",
       " ['i', 'know', 'eep', 'i', 'can', 't', 'wait', 'for', 'one', 'more', 'day'],\n",
       " ['so',\n",
       "  'scared',\n",
       "  'and',\n",
       "  'feeling',\n",
       "  'sick',\n",
       "  'fuck',\n",
       "  'hope',\n",
       "  'someone',\n",
       "  'at',\n",
       "  'hr',\n",
       "  'help',\n",
       "  'wish',\n",
       "  'it',\n",
       "  'would',\n",
       "  'be',\n",
       "  'wendita',\n",
       "  'or',\n",
       "  'karen']]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts = [[word for word in text.split()] for text in wordlist]\n",
    "texts[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "去掉只出現一次的單詞"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['are', 'wtf', 'awww', 'thanks'],\n",
       " ['leavingg',\n",
       "  'to',\n",
       "  'wait',\n",
       "  'for',\n",
       "  'to',\n",
       "  'arrive',\n",
       "  'myspacin',\n",
       "  'itt',\n",
       "  'for',\n",
       "  'now'],\n",
       " ['i',\n",
       "  'wish',\n",
       "  'i',\n",
       "  'could',\n",
       "  'go',\n",
       "  'and',\n",
       "  'see',\n",
       "  'duffy',\n",
       "  'when',\n",
       "  'she',\n",
       "  'comes',\n",
       "  'to',\n",
       "  'mamaia',\n",
       "  'romania'],\n",
       " ['i', 'know', 'eep', 'i', 'can', 't', 'wait', 'for', 'one', 'more', 'day'],\n",
       " ['so',\n",
       "  'scared',\n",
       "  'and',\n",
       "  'feeling',\n",
       "  'sick',\n",
       "  'fuck',\n",
       "  'hope',\n",
       "  'someone',\n",
       "  'at',\n",
       "  'hr',\n",
       "  'help',\n",
       "  'wish',\n",
       "  'it',\n",
       "  'would',\n",
       "  'be',\n",
       "  'wendita',\n",
       "  'or',\n",
       "  'karen']]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frequency = defaultdict(int)\n",
    "\n",
    "for text in texts:\n",
    "    for token in text:\n",
    "        frequency[token] += 1\n",
    "\n",
    "texts = [[token for token in text if frequency[token] > 1] for text in texts]\n",
    "texts[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "儲存成字典"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-04-03 22:01:28,151 : INFO : collecting all words and their counts\n",
      "2019-04-03 22:01:28,152 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2019-04-03 22:01:28,169 : INFO : PROGRESS: at sentence #10000, processed 130409 words, keeping 12779 word types\n",
      "2019-04-03 22:01:28,186 : INFO : PROGRESS: at sentence #20000, processed 260264 words, keeping 19206 word types\n",
      "2019-04-03 22:01:28,205 : INFO : PROGRESS: at sentence #30000, processed 390139 words, keeping 24259 word types\n",
      "2019-04-03 22:01:28,224 : INFO : PROGRESS: at sentence #40000, processed 520247 words, keeping 28556 word types\n",
      "2019-04-03 22:01:28,243 : INFO : PROGRESS: at sentence #50000, processed 649085 words, keeping 32366 word types\n",
      "2019-04-03 22:01:28,259 : INFO : PROGRESS: at sentence #60000, processed 779859 words, keeping 35858 word types\n",
      "2019-04-03 22:01:28,277 : INFO : PROGRESS: at sentence #70000, processed 910947 words, keeping 39113 word types\n",
      "2019-04-03 22:01:28,296 : INFO : PROGRESS: at sentence #80000, processed 1039763 words, keeping 42033 word types\n",
      "2019-04-03 22:01:28,313 : INFO : PROGRESS: at sentence #90000, processed 1168463 words, keeping 44876 word types\n",
      "2019-04-03 22:01:28,332 : INFO : PROGRESS: at sentence #100000, processed 1298171 words, keeping 47589 word types\n",
      "2019-04-03 22:01:28,351 : INFO : PROGRESS: at sentence #110000, processed 1427027 words, keeping 50120 word types\n",
      "2019-04-03 22:01:28,370 : INFO : PROGRESS: at sentence #120000, processed 1557392 words, keeping 52662 word types\n",
      "2019-04-03 22:01:28,388 : INFO : PROGRESS: at sentence #130000, processed 1686742 words, keeping 54946 word types\n",
      "2019-04-03 22:01:28,407 : INFO : PROGRESS: at sentence #140000, processed 1816714 words, keeping 57275 word types\n",
      "2019-04-03 22:01:28,426 : INFO : PROGRESS: at sentence #150000, processed 1947363 words, keeping 59540 word types\n",
      "2019-04-03 22:01:28,442 : INFO : PROGRESS: at sentence #160000, processed 2075318 words, keeping 61630 word types\n",
      "2019-04-03 22:01:28,459 : INFO : PROGRESS: at sentence #170000, processed 2205261 words, keeping 63700 word types\n",
      "2019-04-03 22:01:28,478 : INFO : PROGRESS: at sentence #180000, processed 2335498 words, keeping 65680 word types\n",
      "2019-04-03 22:01:28,494 : INFO : PROGRESS: at sentence #190000, processed 2464607 words, keeping 67588 word types\n",
      "2019-04-03 22:01:28,513 : INFO : PROGRESS: at sentence #200000, processed 2595487 words, keeping 69528 word types\n",
      "2019-04-03 22:01:28,528 : INFO : PROGRESS: at sentence #210000, processed 2701856 words, keeping 70500 word types\n",
      "2019-04-03 22:01:28,542 : INFO : PROGRESS: at sentence #220000, processed 2808110 words, keeping 71406 word types\n",
      "2019-04-03 22:01:28,557 : INFO : PROGRESS: at sentence #230000, processed 2914347 words, keeping 72295 word types\n",
      "2019-04-03 22:01:28,573 : INFO : PROGRESS: at sentence #240000, processed 3021298 words, keeping 73219 word types\n",
      "2019-04-03 22:01:28,586 : INFO : PROGRESS: at sentence #250000, processed 3126416 words, keeping 74137 word types\n",
      "2019-04-03 22:01:28,601 : INFO : PROGRESS: at sentence #260000, processed 3231913 words, keeping 74952 word types\n",
      "2019-04-03 22:01:28,617 : INFO : PROGRESS: at sentence #270000, processed 3338698 words, keeping 75794 word types\n",
      "2019-04-03 22:01:28,631 : INFO : PROGRESS: at sentence #280000, processed 3444753 words, keeping 76576 word types\n",
      "2019-04-03 22:01:28,648 : INFO : PROGRESS: at sentence #290000, processed 3552147 words, keeping 77355 word types\n",
      "2019-04-03 22:01:28,663 : INFO : PROGRESS: at sentence #300000, processed 3658405 words, keeping 78129 word types\n",
      "2019-04-03 22:01:28,676 : INFO : PROGRESS: at sentence #310000, processed 3764118 words, keeping 78906 word types\n",
      "2019-04-03 22:01:28,693 : INFO : PROGRESS: at sentence #320000, processed 3869702 words, keeping 79619 word types\n",
      "2019-04-03 22:01:28,707 : INFO : PROGRESS: at sentence #330000, processed 3975996 words, keeping 80343 word types\n",
      "2019-04-03 22:01:28,721 : INFO : PROGRESS: at sentence #340000, processed 4082598 words, keeping 81066 word types\n",
      "2019-04-03 22:01:28,736 : INFO : PROGRESS: at sentence #350000, processed 4189660 words, keeping 81736 word types\n",
      "2019-04-03 22:01:28,752 : INFO : PROGRESS: at sentence #360000, processed 4296803 words, keeping 82428 word types\n",
      "2019-04-03 22:01:28,765 : INFO : PROGRESS: at sentence #370000, processed 4401855 words, keeping 83102 word types\n",
      "2019-04-03 22:01:28,780 : INFO : PROGRESS: at sentence #380000, processed 4508643 words, keeping 83805 word types\n",
      "2019-04-03 22:01:28,796 : INFO : PROGRESS: at sentence #390000, processed 4614311 words, keeping 84472 word types\n",
      "2019-04-03 22:01:28,810 : INFO : PROGRESS: at sentence #400000, processed 4720971 words, keeping 85110 word types\n",
      "2019-04-03 22:01:28,827 : INFO : PROGRESS: at sentence #410000, processed 4827314 words, keeping 85734 word types\n",
      "2019-04-03 22:01:28,842 : INFO : PROGRESS: at sentence #420000, processed 4934012 words, keeping 86307 word types\n",
      "2019-04-03 22:01:28,856 : INFO : PROGRESS: at sentence #430000, processed 5041281 words, keeping 86938 word types\n",
      "2019-04-03 22:01:28,871 : INFO : PROGRESS: at sentence #440000, processed 5147813 words, keeping 87554 word types\n",
      "2019-04-03 22:01:28,888 : INFO : PROGRESS: at sentence #450000, processed 5253911 words, keeping 88136 word types\n",
      "2019-04-03 22:01:28,902 : INFO : PROGRESS: at sentence #460000, processed 5360661 words, keeping 88695 word types\n",
      "2019-04-03 22:01:28,919 : INFO : PROGRESS: at sentence #470000, processed 5466240 words, keeping 89229 word types\n",
      "2019-04-03 22:01:28,936 : INFO : PROGRESS: at sentence #480000, processed 5572306 words, keeping 89770 word types\n",
      "2019-04-03 22:01:28,952 : INFO : PROGRESS: at sentence #490000, processed 5679129 words, keeping 90323 word types\n",
      "2019-04-03 22:01:28,967 : INFO : PROGRESS: at sentence #500000, processed 5786789 words, keeping 90865 word types\n",
      "2019-04-03 22:01:28,983 : INFO : PROGRESS: at sentence #510000, processed 5893549 words, keeping 91367 word types\n",
      "2019-04-03 22:01:28,997 : INFO : PROGRESS: at sentence #520000, processed 6000776 words, keeping 91908 word types\n",
      "2019-04-03 22:01:29,011 : INFO : PROGRESS: at sentence #530000, processed 6107931 words, keeping 92436 word types\n",
      "2019-04-03 22:01:29,028 : INFO : PROGRESS: at sentence #540000, processed 6212947 words, keeping 92953 word types\n",
      "2019-04-03 22:01:29,042 : INFO : PROGRESS: at sentence #550000, processed 6319426 words, keeping 93520 word types\n",
      "2019-04-03 22:01:29,057 : INFO : PROGRESS: at sentence #560000, processed 6425692 words, keeping 94048 word types\n",
      "2019-04-03 22:01:29,074 : INFO : PROGRESS: at sentence #570000, processed 6530994 words, keeping 94498 word types\n",
      "2019-04-03 22:01:29,088 : INFO : PROGRESS: at sentence #580000, processed 6637400 words, keeping 94971 word types\n",
      "2019-04-03 22:01:29,103 : INFO : PROGRESS: at sentence #590000, processed 6743327 words, keeping 95410 word types\n",
      "2019-04-03 22:01:29,119 : INFO : PROGRESS: at sentence #600000, processed 6849462 words, keeping 95858 word types\n",
      "2019-04-03 22:01:29,133 : INFO : PROGRESS: at sentence #610000, processed 6955782 words, keeping 96307 word types\n",
      "2019-04-03 22:01:29,148 : INFO : PROGRESS: at sentence #620000, processed 7063024 words, keeping 96740 word types\n",
      "2019-04-03 22:01:29,165 : INFO : PROGRESS: at sentence #630000, processed 7168932 words, keeping 97170 word types\n",
      "2019-04-03 22:01:29,180 : INFO : PROGRESS: at sentence #640000, processed 7275536 words, keeping 97626 word types\n",
      "2019-04-03 22:01:29,195 : INFO : PROGRESS: at sentence #650000, processed 7383730 words, keeping 98045 word types\n",
      "2019-04-03 22:01:29,211 : INFO : PROGRESS: at sentence #660000, processed 7490570 words, keeping 98489 word types\n",
      "2019-04-03 22:01:29,225 : INFO : PROGRESS: at sentence #670000, processed 7596450 words, keeping 98881 word types\n",
      "2019-04-03 22:01:29,242 : INFO : PROGRESS: at sentence #680000, processed 7702641 words, keeping 99289 word types\n",
      "2019-04-03 22:01:29,259 : INFO : PROGRESS: at sentence #690000, processed 7808325 words, keeping 99694 word types\n",
      "2019-04-03 22:01:29,274 : INFO : PROGRESS: at sentence #700000, processed 7915299 words, keeping 100120 word types\n",
      "2019-04-03 22:01:29,289 : INFO : PROGRESS: at sentence #710000, processed 8021883 words, keeping 100526 word types\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-04-03 22:01:29,304 : INFO : PROGRESS: at sentence #720000, processed 8127600 words, keeping 100966 word types\n",
      "2019-04-03 22:01:29,320 : INFO : PROGRESS: at sentence #730000, processed 8233858 words, keeping 101342 word types\n",
      "2019-04-03 22:01:29,334 : INFO : PROGRESS: at sentence #740000, processed 8340314 words, keeping 101729 word types\n",
      "2019-04-03 22:01:29,350 : INFO : PROGRESS: at sentence #750000, processed 8446382 words, keeping 102093 word types\n",
      "2019-04-03 22:01:29,364 : INFO : PROGRESS: at sentence #760000, processed 8551312 words, keeping 102484 word types\n",
      "2019-04-03 22:01:29,381 : INFO : PROGRESS: at sentence #770000, processed 8658386 words, keeping 102847 word types\n",
      "2019-04-03 22:01:29,397 : INFO : PROGRESS: at sentence #780000, processed 8764306 words, keeping 103193 word types\n",
      "2019-04-03 22:01:29,411 : INFO : PROGRESS: at sentence #790000, processed 8871070 words, keeping 103523 word types\n",
      "2019-04-03 22:01:29,426 : INFO : PROGRESS: at sentence #800000, processed 8977603 words, keeping 103871 word types\n",
      "2019-04-03 22:01:29,443 : INFO : PROGRESS: at sentence #810000, processed 9082525 words, keeping 104199 word types\n",
      "2019-04-03 22:01:29,460 : INFO : PROGRESS: at sentence #820000, processed 9188576 words, keeping 104549 word types\n",
      "2019-04-03 22:01:29,474 : INFO : PROGRESS: at sentence #830000, processed 9295070 words, keeping 104858 word types\n",
      "2019-04-03 22:01:29,489 : INFO : PROGRESS: at sentence #840000, processed 9402306 words, keeping 105173 word types\n",
      "2019-04-03 22:01:29,504 : INFO : PROGRESS: at sentence #850000, processed 9509206 words, keeping 105550 word types\n",
      "2019-04-03 22:01:29,520 : INFO : PROGRESS: at sentence #860000, processed 9616806 words, keeping 105886 word types\n",
      "2019-04-03 22:01:29,534 : INFO : PROGRESS: at sentence #870000, processed 9722872 words, keeping 106202 word types\n",
      "2019-04-03 22:01:29,551 : INFO : PROGRESS: at sentence #880000, processed 9829759 words, keeping 106514 word types\n",
      "2019-04-03 22:01:29,565 : INFO : PROGRESS: at sentence #890000, processed 9936250 words, keeping 106797 word types\n",
      "2019-04-03 22:01:29,580 : INFO : PROGRESS: at sentence #900000, processed 10042840 words, keeping 107073 word types\n",
      "2019-04-03 22:01:29,596 : INFO : PROGRESS: at sentence #910000, processed 10149298 words, keeping 107377 word types\n",
      "2019-04-03 22:01:29,611 : INFO : PROGRESS: at sentence #920000, processed 10255633 words, keeping 107698 word types\n",
      "2019-04-03 22:01:29,625 : INFO : PROGRESS: at sentence #930000, processed 10362052 words, keeping 107975 word types\n",
      "2019-04-03 22:01:29,642 : INFO : PROGRESS: at sentence #940000, processed 10467660 words, keeping 108247 word types\n",
      "2019-04-03 22:01:29,657 : INFO : PROGRESS: at sentence #950000, processed 10574447 words, keeping 108541 word types\n",
      "2019-04-03 22:01:29,673 : INFO : PROGRESS: at sentence #960000, processed 10680100 words, keeping 108813 word types\n",
      "2019-04-03 22:01:29,688 : INFO : PROGRESS: at sentence #970000, processed 10786258 words, keeping 109087 word types\n",
      "2019-04-03 22:01:29,702 : INFO : PROGRESS: at sentence #980000, processed 10892145 words, keeping 109384 word types\n",
      "2019-04-03 22:01:29,717 : INFO : PROGRESS: at sentence #990000, processed 10997356 words, keeping 109613 word types\n",
      "2019-04-03 22:01:29,734 : INFO : PROGRESS: at sentence #1000000, processed 11104891 words, keeping 109870 word types\n",
      "2019-04-03 22:01:29,749 : INFO : PROGRESS: at sentence #1010000, processed 11210632 words, keeping 110135 word types\n",
      "2019-04-03 22:01:29,765 : INFO : PROGRESS: at sentence #1020000, processed 11317705 words, keeping 110398 word types\n",
      "2019-04-03 22:01:29,782 : INFO : PROGRESS: at sentence #1030000, processed 11425451 words, keeping 110643 word types\n",
      "2019-04-03 22:01:29,797 : INFO : PROGRESS: at sentence #1040000, processed 11532406 words, keeping 110883 word types\n",
      "2019-04-03 22:01:29,811 : INFO : PROGRESS: at sentence #1050000, processed 11639095 words, keeping 111133 word types\n",
      "2019-04-03 22:01:29,827 : INFO : PROGRESS: at sentence #1060000, processed 11744516 words, keeping 111352 word types\n",
      "2019-04-03 22:01:29,842 : INFO : PROGRESS: at sentence #1070000, processed 11851519 words, keeping 111599 word types\n",
      "2019-04-03 22:01:29,856 : INFO : PROGRESS: at sentence #1080000, processed 11958336 words, keeping 111825 word types\n",
      "2019-04-03 22:01:29,872 : INFO : PROGRESS: at sentence #1090000, processed 12065204 words, keeping 112051 word types\n",
      "2019-04-03 22:01:29,887 : INFO : PROGRESS: at sentence #1100000, processed 12171651 words, keeping 112295 word types\n",
      "2019-04-03 22:01:29,902 : INFO : PROGRESS: at sentence #1110000, processed 12278819 words, keeping 112509 word types\n",
      "2019-04-03 22:01:29,921 : INFO : PROGRESS: at sentence #1120000, processed 12384643 words, keeping 112724 word types\n",
      "2019-04-03 22:01:29,935 : INFO : PROGRESS: at sentence #1130000, processed 12491183 words, keeping 112929 word types\n",
      "2019-04-03 22:01:29,949 : INFO : PROGRESS: at sentence #1140000, processed 12598152 words, keeping 113151 word types\n",
      "2019-04-03 22:01:29,967 : INFO : PROGRESS: at sentence #1150000, processed 12705072 words, keeping 113373 word types\n",
      "2019-04-03 22:01:29,981 : INFO : PROGRESS: at sentence #1160000, processed 12811804 words, keeping 113577 word types\n",
      "2019-04-03 22:01:29,995 : INFO : PROGRESS: at sentence #1170000, processed 12918665 words, keeping 113803 word types\n",
      "2019-04-03 22:01:30,011 : INFO : PROGRESS: at sentence #1180000, processed 13025322 words, keeping 114009 word types\n",
      "2019-04-03 22:01:30,025 : INFO : PROGRESS: at sentence #1190000, processed 13131503 words, keeping 114200 word types\n",
      "2019-04-03 22:01:30,041 : INFO : PROGRESS: at sentence #1200000, processed 13237861 words, keeping 114383 word types\n",
      "2019-04-03 22:01:30,056 : INFO : PROGRESS: at sentence #1210000, processed 13345495 words, keeping 114586 word types\n",
      "2019-04-03 22:01:30,071 : INFO : PROGRESS: at sentence #1220000, processed 13452010 words, keeping 114795 word types\n",
      "2019-04-03 22:01:30,085 : INFO : PROGRESS: at sentence #1230000, processed 13558379 words, keeping 114989 word types\n",
      "2019-04-03 22:01:30,101 : INFO : PROGRESS: at sentence #1240000, processed 13664702 words, keeping 115180 word types\n",
      "2019-04-03 22:01:30,116 : INFO : PROGRESS: at sentence #1250000, processed 13771134 words, keeping 115367 word types\n",
      "2019-04-03 22:01:30,130 : INFO : PROGRESS: at sentence #1260000, processed 13876378 words, keeping 115556 word types\n",
      "2019-04-03 22:01:30,146 : INFO : PROGRESS: at sentence #1270000, processed 13983824 words, keeping 115731 word types\n",
      "2019-04-03 22:01:30,161 : INFO : PROGRESS: at sentence #1280000, processed 14090534 words, keeping 115914 word types\n",
      "2019-04-03 22:01:30,178 : INFO : PROGRESS: at sentence #1290000, processed 14197552 words, keeping 116084 word types\n",
      "2019-04-03 22:01:30,194 : INFO : PROGRESS: at sentence #1300000, processed 14303663 words, keeping 116239 word types\n",
      "2019-04-03 22:01:30,209 : INFO : PROGRESS: at sentence #1310000, processed 14409840 words, keeping 116425 word types\n",
      "2019-04-03 22:01:30,223 : INFO : PROGRESS: at sentence #1320000, processed 14517104 words, keeping 116607 word types\n",
      "2019-04-03 22:01:30,237 : INFO : PROGRESS: at sentence #1330000, processed 14622815 words, keeping 116794 word types\n",
      "2019-04-03 22:01:30,255 : INFO : PROGRESS: at sentence #1340000, processed 14730732 words, keeping 116948 word types\n",
      "2019-04-03 22:01:30,269 : INFO : PROGRESS: at sentence #1350000, processed 14840450 words, keeping 117071 word types\n",
      "2019-04-03 22:01:30,286 : INFO : PROGRESS: at sentence #1360000, processed 14969204 words, keeping 117090 word types\n",
      "2019-04-03 22:01:30,305 : INFO : PROGRESS: at sentence #1370000, processed 15098025 words, keeping 117103 word types\n",
      "2019-04-03 22:01:30,324 : INFO : PROGRESS: at sentence #1380000, processed 15226510 words, keeping 117120 word types\n",
      "2019-04-03 22:01:30,342 : INFO : PROGRESS: at sentence #1390000, processed 15356925 words, keeping 117133 word types\n",
      "2019-04-03 22:01:30,359 : INFO : PROGRESS: at sentence #1400000, processed 15487156 words, keeping 117146 word types\n",
      "2019-04-03 22:01:30,377 : INFO : PROGRESS: at sentence #1410000, processed 15616622 words, keeping 117162 word types\n",
      "2019-04-03 22:01:30,397 : INFO : PROGRESS: at sentence #1420000, processed 15745735 words, keeping 117174 word types\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-04-03 22:01:30,414 : INFO : PROGRESS: at sentence #1430000, processed 15874847 words, keeping 117182 word types\n",
      "2019-04-03 22:01:30,432 : INFO : PROGRESS: at sentence #1440000, processed 16003952 words, keeping 117193 word types\n",
      "2019-04-03 22:01:30,451 : INFO : PROGRESS: at sentence #1450000, processed 16133626 words, keeping 117205 word types\n",
      "2019-04-03 22:01:30,468 : INFO : PROGRESS: at sentence #1460000, processed 16264033 words, keeping 117217 word types\n",
      "2019-04-03 22:01:30,485 : INFO : PROGRESS: at sentence #1470000, processed 16392236 words, keeping 117223 word types\n",
      "2019-04-03 22:01:30,507 : INFO : PROGRESS: at sentence #1480000, processed 16521008 words, keeping 117235 word types\n",
      "2019-04-03 22:01:30,524 : INFO : PROGRESS: at sentence #1490000, processed 16650611 words, keeping 117247 word types\n",
      "2019-04-03 22:01:30,543 : INFO : PROGRESS: at sentence #1500000, processed 16781127 words, keeping 117257 word types\n",
      "2019-04-03 22:01:30,560 : INFO : PROGRESS: at sentence #1510000, processed 16911160 words, keeping 117264 word types\n",
      "2019-04-03 22:01:30,577 : INFO : PROGRESS: at sentence #1520000, processed 17040171 words, keeping 117273 word types\n",
      "2019-04-03 22:01:30,597 : INFO : PROGRESS: at sentence #1530000, processed 17170372 words, keeping 117282 word types\n",
      "2019-04-03 22:01:30,613 : INFO : PROGRESS: at sentence #1540000, processed 17300219 words, keeping 117284 word types\n",
      "2019-04-03 22:01:30,628 : INFO : collected 117286 word types from a corpus of 17408254 raw words and 1548451 sentences\n",
      "2019-04-03 22:01:30,628 : INFO : Loading a fresh vocabulary\n",
      "2019-04-03 22:01:30,739 : INFO : effective_min_count=1 retains 117286 unique words (100% of original 117286, drops 0)\n",
      "2019-04-03 22:01:30,739 : INFO : effective_min_count=1 leaves 17408254 word corpus (100% of original 17408254, drops 0)\n",
      "2019-04-03 22:01:30,953 : INFO : deleting the raw counts dictionary of 117286 items\n",
      "2019-04-03 22:01:30,956 : INFO : sample=0.001 downsamples 56 most-common words\n",
      "2019-04-03 22:01:30,956 : INFO : downsampling leaves estimated 13498947 word corpus (77.5% of prior 17408254)\n",
      "2019-04-03 22:01:31,190 : INFO : estimated required memory for 117286 words and 200 dimensions: 246300600 bytes\n",
      "2019-04-03 22:01:31,190 : INFO : resetting layer weights\n",
      "2019-04-03 22:01:32,052 : INFO : training model with 6 workers on 117286 vocabulary and 200 features, using sg=1 hs=0 sample=0.001 negative=5 window=3\n",
      "2019-04-03 22:01:33,064 : INFO : EPOCH 1 - PROGRESS: at 7.01% examples, 1086380 words/s, in_qsize 11, out_qsize 0\n",
      "2019-04-03 22:01:34,071 : INFO : EPOCH 1 - PROGRESS: at 14.33% examples, 1089615 words/s, in_qsize 11, out_qsize 0\n",
      "2019-04-03 22:01:35,085 : INFO : EPOCH 1 - PROGRESS: at 23.07% examples, 1093556 words/s, in_qsize 10, out_qsize 1\n",
      "2019-04-03 22:01:36,087 : INFO : EPOCH 1 - PROGRESS: at 30.72% examples, 1063847 words/s, in_qsize 12, out_qsize 0\n",
      "2019-04-03 22:01:37,095 : INFO : EPOCH 1 - PROGRESS: at 39.57% examples, 1075806 words/s, in_qsize 11, out_qsize 0\n",
      "2019-04-03 22:01:38,108 : INFO : EPOCH 1 - PROGRESS: at 48.60% examples, 1086494 words/s, in_qsize 11, out_qsize 0\n",
      "2019-04-03 22:01:39,116 : INFO : EPOCH 1 - PROGRESS: at 57.46% examples, 1091665 words/s, in_qsize 11, out_qsize 0\n",
      "2019-04-03 22:01:40,127 : INFO : EPOCH 1 - PROGRESS: at 66.44% examples, 1097021 words/s, in_qsize 11, out_qsize 0\n",
      "2019-04-03 22:01:41,132 : INFO : EPOCH 1 - PROGRESS: at 75.39% examples, 1101885 words/s, in_qsize 11, out_qsize 0\n",
      "2019-04-03 22:01:42,138 : INFO : EPOCH 1 - PROGRESS: at 84.05% examples, 1101895 words/s, in_qsize 11, out_qsize 0\n",
      "2019-04-03 22:01:43,144 : INFO : EPOCH 1 - PROGRESS: at 91.87% examples, 1103866 words/s, in_qsize 11, out_qsize 0\n",
      "2019-04-03 22:01:44,152 : INFO : EPOCH 1 - PROGRESS: at 99.04% examples, 1104099 words/s, in_qsize 11, out_qsize 0\n",
      "2019-04-03 22:01:44,260 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-04-03 22:01:44,262 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-04-03 22:01:44,270 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-04-03 22:01:44,276 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-04-03 22:01:44,281 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-04-03 22:01:44,291 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-04-03 22:01:44,291 : INFO : EPOCH - 1 : training on 17408254 raw words (13499906 effective words) took 12.2s, 1103633 effective words/s\n",
      "2019-04-03 22:01:45,298 : INFO : EPOCH 2 - PROGRESS: at 6.96% examples, 1082929 words/s, in_qsize 11, out_qsize 0\n",
      "2019-04-03 22:01:46,305 : INFO : EPOCH 2 - PROGRESS: at 14.33% examples, 1092203 words/s, in_qsize 11, out_qsize 0\n",
      "2019-04-03 22:01:47,311 : INFO : EPOCH 2 - PROGRESS: at 23.13% examples, 1100361 words/s, in_qsize 11, out_qsize 0\n",
      "2019-04-03 22:01:48,314 : INFO : EPOCH 2 - PROGRESS: at 31.81% examples, 1101364 words/s, in_qsize 11, out_qsize 0\n",
      "2019-04-03 22:01:49,317 : INFO : EPOCH 2 - PROGRESS: at 40.48% examples, 1102244 words/s, in_qsize 11, out_qsize 0\n",
      "2019-04-03 22:01:50,322 : INFO : EPOCH 2 - PROGRESS: at 49.16% examples, 1102420 words/s, in_qsize 11, out_qsize 0\n",
      "2019-04-03 22:01:51,324 : INFO : EPOCH 2 - PROGRESS: at 57.76% examples, 1101808 words/s, in_qsize 11, out_qsize 0\n",
      "2019-04-03 22:01:52,329 : INFO : EPOCH 2 - PROGRESS: at 66.62% examples, 1104715 words/s, in_qsize 11, out_qsize 0\n",
      "2019-04-03 22:01:53,332 : INFO : EPOCH 2 - PROGRESS: at 74.12% examples, 1088439 words/s, in_qsize 11, out_qsize 0\n",
      "2019-04-03 22:01:54,332 : INFO : EPOCH 2 - PROGRESS: at 81.27% examples, 1071176 words/s, in_qsize 11, out_qsize 0\n",
      "2019-04-03 22:01:55,340 : INFO : EPOCH 2 - PROGRESS: at 88.48% examples, 1060448 words/s, in_qsize 11, out_qsize 0\n",
      "2019-04-03 22:01:56,342 : INFO : EPOCH 2 - PROGRESS: at 94.41% examples, 1048723 words/s, in_qsize 11, out_qsize 0\n",
      "2019-04-03 22:01:57,229 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-04-03 22:01:57,237 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-04-03 22:01:57,245 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-04-03 22:01:57,247 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-04-03 22:01:57,253 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-04-03 22:01:57,274 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-04-03 22:01:57,275 : INFO : EPOCH - 2 : training on 17408254 raw words (13498953 effective words) took 13.0s, 1040186 effective words/s\n",
      "2019-04-03 22:01:58,289 : INFO : EPOCH 3 - PROGRESS: at 5.86% examples, 907834 words/s, in_qsize 11, out_qsize 0\n",
      "2019-04-03 22:01:59,297 : INFO : EPOCH 3 - PROGRESS: at 11.84% examples, 915166 words/s, in_qsize 11, out_qsize 0\n",
      "2019-04-03 22:02:00,308 : INFO : EPOCH 3 - PROGRESS: at 18.95% examples, 919317 words/s, in_qsize 11, out_qsize 0\n",
      "2019-04-03 22:02:01,313 : INFO : EPOCH 3 - PROGRESS: at 26.65% examples, 934194 words/s, in_qsize 11, out_qsize 0\n",
      "2019-04-03 22:02:02,322 : INFO : EPOCH 3 - PROGRESS: at 35.62% examples, 974814 words/s, in_qsize 11, out_qsize 0\n",
      "2019-04-03 22:02:03,328 : INFO : EPOCH 3 - PROGRESS: at 44.54% examples, 1001100 words/s, in_qsize 11, out_qsize 0\n",
      "2019-04-03 22:02:04,336 : INFO : EPOCH 3 - PROGRESS: at 53.53% examples, 1020482 words/s, in_qsize 11, out_qsize 0\n",
      "2019-04-03 22:02:05,339 : INFO : EPOCH 3 - PROGRESS: at 62.37% examples, 1033967 words/s, in_qsize 11, out_qsize 0\n",
      "2019-04-03 22:02:06,340 : INFO : EPOCH 3 - PROGRESS: at 71.16% examples, 1043797 words/s, in_qsize 11, out_qsize 0\n",
      "2019-04-03 22:02:07,345 : INFO : EPOCH 3 - PROGRESS: at 79.99% examples, 1051947 words/s, in_qsize 11, out_qsize 0\n",
      "2019-04-03 22:02:08,352 : INFO : EPOCH 3 - PROGRESS: at 88.38% examples, 1056423 words/s, in_qsize 11, out_qsize 0\n",
      "2019-04-03 22:02:09,360 : INFO : EPOCH 3 - PROGRESS: at 94.26% examples, 1043945 words/s, in_qsize 11, out_qsize 0\n",
      "2019-04-03 22:02:10,291 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-04-03 22:02:10,307 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-04-03 22:02:10,310 : INFO : worker thread finished; awaiting finish of 3 more threads\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-04-03 22:02:10,315 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-04-03 22:02:10,321 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-04-03 22:02:10,323 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-04-03 22:02:10,323 : INFO : EPOCH - 3 : training on 17408254 raw words (13499875 effective words) took 13.0s, 1035195 effective words/s\n",
      "2019-04-03 22:02:11,332 : INFO : EPOCH 4 - PROGRESS: at 5.71% examples, 889515 words/s, in_qsize 11, out_qsize 0\n",
      "2019-04-03 22:02:12,334 : INFO : EPOCH 4 - PROGRESS: at 11.74% examples, 912116 words/s, in_qsize 11, out_qsize 0\n",
      "2019-04-03 22:02:13,336 : INFO : EPOCH 4 - PROGRESS: at 18.46% examples, 904762 words/s, in_qsize 11, out_qsize 0\n",
      "2019-04-03 22:02:14,336 : INFO : EPOCH 4 - PROGRESS: at 25.81% examples, 912974 words/s, in_qsize 11, out_qsize 0\n",
      "2019-04-03 22:02:15,339 : INFO : EPOCH 4 - PROGRESS: at 33.07% examples, 915782 words/s, in_qsize 11, out_qsize 0\n",
      "2019-04-03 22:02:16,342 : INFO : EPOCH 4 - PROGRESS: at 40.41% examples, 918955 words/s, in_qsize 11, out_qsize 0\n",
      "2019-04-03 22:02:17,352 : INFO : EPOCH 4 - PROGRESS: at 47.87% examples, 922485 words/s, in_qsize 11, out_qsize 0\n",
      "2019-04-03 22:02:18,355 : INFO : EPOCH 4 - PROGRESS: at 55.22% examples, 923983 words/s, in_qsize 11, out_qsize 0\n",
      "2019-04-03 22:02:19,364 : INFO : EPOCH 4 - PROGRESS: at 62.37% examples, 922084 words/s, in_qsize 11, out_qsize 0\n",
      "2019-04-03 22:02:20,365 : INFO : EPOCH 4 - PROGRESS: at 68.61% examples, 909663 words/s, in_qsize 11, out_qsize 0\n",
      "2019-04-03 22:02:21,369 : INFO : EPOCH 4 - PROGRESS: at 75.93% examples, 911780 words/s, in_qsize 11, out_qsize 0\n",
      "2019-04-03 22:02:22,370 : INFO : EPOCH 4 - PROGRESS: at 83.26% examples, 913939 words/s, in_qsize 11, out_qsize 0\n",
      "2019-04-03 22:02:23,392 : INFO : EPOCH 4 - PROGRESS: at 89.93% examples, 913593 words/s, in_qsize 11, out_qsize 0\n",
      "2019-04-03 22:02:24,396 : INFO : EPOCH 4 - PROGRESS: at 95.72% examples, 912211 words/s, in_qsize 11, out_qsize 0\n",
      "2019-04-03 22:02:25,107 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-04-03 22:02:25,111 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-04-03 22:02:25,113 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-04-03 22:02:25,120 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-04-03 22:02:25,129 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-04-03 22:02:25,141 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-04-03 22:02:25,141 : INFO : EPOCH - 4 : training on 17408254 raw words (13498051 effective words) took 14.8s, 911356 effective words/s\n",
      "2019-04-03 22:02:26,156 : INFO : EPOCH 5 - PROGRESS: at 5.72% examples, 883588 words/s, in_qsize 11, out_qsize 0\n",
      "2019-04-03 22:02:27,165 : INFO : EPOCH 5 - PROGRESS: at 11.64% examples, 898586 words/s, in_qsize 11, out_qsize 0\n",
      "2019-04-03 22:02:28,166 : INFO : EPOCH 5 - PROGRESS: at 20.10% examples, 970512 words/s, in_qsize 11, out_qsize 0\n",
      "2019-04-03 22:02:29,168 : INFO : EPOCH 5 - PROGRESS: at 28.77% examples, 1004307 words/s, in_qsize 11, out_qsize 0\n",
      "2019-04-03 22:02:30,182 : INFO : EPOCH 5 - PROGRESS: at 37.44% examples, 1022023 words/s, in_qsize 11, out_qsize 0\n",
      "2019-04-03 22:02:31,186 : INFO : EPOCH 5 - PROGRESS: at 46.17% examples, 1037032 words/s, in_qsize 11, out_qsize 0\n",
      "2019-04-03 22:02:32,192 : INFO : EPOCH 5 - PROGRESS: at 55.04% examples, 1049423 words/s, in_qsize 11, out_qsize 0\n",
      "2019-04-03 22:02:33,193 : INFO : EPOCH 5 - PROGRESS: at 63.90% examples, 1059584 words/s, in_qsize 11, out_qsize 0\n",
      "2019-04-03 22:02:34,193 : INFO : EPOCH 5 - PROGRESS: at 72.67% examples, 1066654 words/s, in_qsize 11, out_qsize 0\n",
      "2019-04-03 22:02:35,196 : INFO : EPOCH 5 - PROGRESS: at 81.51% examples, 1072801 words/s, in_qsize 11, out_qsize 0\n",
      "2019-04-03 22:02:36,203 : INFO : EPOCH 5 - PROGRESS: at 89.68% examples, 1076000 words/s, in_qsize 11, out_qsize 0\n",
      "2019-04-03 22:02:37,212 : INFO : EPOCH 5 - PROGRESS: at 96.81% examples, 1077827 words/s, in_qsize 11, out_qsize 0\n",
      "2019-04-03 22:02:37,628 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-04-03 22:02:37,637 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-04-03 22:02:37,640 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-04-03 22:02:37,642 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-04-03 22:02:37,651 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-04-03 22:02:37,657 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-04-03 22:02:37,658 : INFO : EPOCH - 5 : training on 17408254 raw words (13497949 effective words) took 12.5s, 1079050 effective words/s\n",
      "2019-04-03 22:02:38,668 : INFO : EPOCH 6 - PROGRESS: at 7.01% examples, 1089562 words/s, in_qsize 11, out_qsize 0\n",
      "2019-04-03 22:02:39,676 : INFO : EPOCH 6 - PROGRESS: at 14.45% examples, 1098278 words/s, in_qsize 11, out_qsize 0\n",
      "2019-04-03 22:02:40,676 : INFO : EPOCH 6 - PROGRESS: at 23.37% examples, 1111494 words/s, in_qsize 11, out_qsize 0\n",
      "2019-04-03 22:02:41,686 : INFO : EPOCH 6 - PROGRESS: at 32.22% examples, 1113847 words/s, in_qsize 11, out_qsize 0\n",
      "2019-04-03 22:02:42,693 : INFO : EPOCH 6 - PROGRESS: at 41.15% examples, 1117290 words/s, in_qsize 11, out_qsize 0\n",
      "2019-04-03 22:02:43,698 : INFO : EPOCH 6 - PROGRESS: at 50.12% examples, 1121307 words/s, in_qsize 11, out_qsize 0\n",
      "2019-04-03 22:02:44,699 : INFO : EPOCH 6 - PROGRESS: at 58.97% examples, 1122678 words/s, in_qsize 11, out_qsize 0\n",
      "2019-04-03 22:02:45,702 : INFO : EPOCH 6 - PROGRESS: at 67.83% examples, 1123327 words/s, in_qsize 11, out_qsize 0\n",
      "2019-04-03 22:02:46,705 : INFO : EPOCH 6 - PROGRESS: at 76.66% examples, 1123877 words/s, in_qsize 11, out_qsize 0\n",
      "2019-04-03 22:02:47,719 : INFO : EPOCH 6 - PROGRESS: at 85.57% examples, 1123844 words/s, in_qsize 11, out_qsize 0\n",
      "2019-04-03 22:02:48,721 : INFO : EPOCH 6 - PROGRESS: at 92.97% examples, 1122138 words/s, in_qsize 11, out_qsize 0\n",
      "2019-04-03 22:02:49,675 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-04-03 22:02:49,677 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-04-03 22:02:49,681 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-04-03 22:02:49,687 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-04-03 22:02:49,695 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-04-03 22:02:49,700 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-04-03 22:02:49,706 : INFO : EPOCH - 6 : training on 17408254 raw words (13498017 effective words) took 12.0s, 1121059 effective words/s\n",
      "2019-04-03 22:02:50,714 : INFO : EPOCH 7 - PROGRESS: at 6.91% examples, 1076529 words/s, in_qsize 11, out_qsize 0\n",
      "2019-04-03 22:02:51,719 : INFO : EPOCH 7 - PROGRESS: at 14.27% examples, 1088913 words/s, in_qsize 11, out_qsize 0\n",
      "2019-04-03 22:02:52,725 : INFO : EPOCH 7 - PROGRESS: at 23.19% examples, 1103490 words/s, in_qsize 11, out_qsize 0\n",
      "2019-04-03 22:02:53,727 : INFO : EPOCH 7 - PROGRESS: at 32.04% examples, 1109791 words/s, in_qsize 11, out_qsize 0\n",
      "2019-04-03 22:02:54,732 : INFO : EPOCH 7 - PROGRESS: at 40.78% examples, 1110034 words/s, in_qsize 11, out_qsize 0\n",
      "2019-04-03 22:02:55,741 : INFO : EPOCH 7 - PROGRESS: at 49.64% examples, 1112006 words/s, in_qsize 11, out_qsize 0\n",
      "2019-04-03 22:02:56,752 : INFO : EPOCH 7 - PROGRESS: at 58.55% examples, 1114217 words/s, in_qsize 11, out_qsize 0\n",
      "2019-04-03 22:02:57,757 : INFO : EPOCH 7 - PROGRESS: at 67.46% examples, 1116420 words/s, in_qsize 11, out_qsize 0\n",
      "2019-04-03 22:02:58,758 : INFO : EPOCH 7 - PROGRESS: at 76.06% examples, 1114488 words/s, in_qsize 11, out_qsize 0\n",
      "2019-04-03 22:02:59,758 : INFO : EPOCH 7 - PROGRESS: at 84.78% examples, 1114562 words/s, in_qsize 11, out_qsize 0\n",
      "2019-04-03 22:03:00,766 : INFO : EPOCH 7 - PROGRESS: at 92.32% examples, 1113229 words/s, in_qsize 11, out_qsize 0\n",
      "2019-04-03 22:03:01,773 : INFO : EPOCH 7 - PROGRESS: at 99.44% examples, 1111989 words/s, in_qsize 11, out_qsize 0\n",
      "2019-04-03 22:03:01,819 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-04-03 22:03:01,828 : INFO : worker thread finished; awaiting finish of 4 more threads\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-04-03 22:03:01,837 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-04-03 22:03:01,838 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-04-03 22:03:01,844 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-04-03 22:03:01,849 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-04-03 22:03:01,849 : INFO : EPOCH - 7 : training on 17408254 raw words (13496376 effective words) took 12.1s, 1112109 effective words/s\n",
      "2019-04-03 22:03:02,861 : INFO : EPOCH 8 - PROGRESS: at 6.91% examples, 1074076 words/s, in_qsize 11, out_qsize 0\n",
      "2019-04-03 22:03:03,868 : INFO : EPOCH 8 - PROGRESS: at 14.33% examples, 1091087 words/s, in_qsize 11, out_qsize 0\n",
      "2019-04-03 22:03:04,870 : INFO : EPOCH 8 - PROGRESS: at 23.25% examples, 1106515 words/s, in_qsize 12, out_qsize 0\n",
      "2019-04-03 22:03:05,875 : INFO : EPOCH 8 - PROGRESS: at 32.10% examples, 1111227 words/s, in_qsize 11, out_qsize 0\n",
      "2019-04-03 22:03:06,880 : INFO : EPOCH 8 - PROGRESS: at 40.97% examples, 1114170 words/s, in_qsize 11, out_qsize 0\n",
      "2019-04-03 22:03:07,881 : INFO : EPOCH 8 - PROGRESS: at 49.76% examples, 1115724 words/s, in_qsize 12, out_qsize 1\n",
      "2019-04-03 22:03:08,883 : INFO : EPOCH 8 - PROGRESS: at 58.67% examples, 1118733 words/s, in_qsize 11, out_qsize 0\n",
      "2019-04-03 22:03:09,886 : INFO : EPOCH 8 - PROGRESS: at 67.52% examples, 1119843 words/s, in_qsize 11, out_qsize 0\n",
      "2019-04-03 22:03:10,896 : INFO : EPOCH 8 - PROGRESS: at 76.42% examples, 1120726 words/s, in_qsize 11, out_qsize 0\n",
      "2019-04-03 22:03:11,901 : INFO : EPOCH 8 - PROGRESS: at 85.32% examples, 1122077 words/s, in_qsize 11, out_qsize 0\n",
      "2019-04-03 22:03:12,904 : INFO : EPOCH 8 - PROGRESS: at 92.77% examples, 1120482 words/s, in_qsize 11, out_qsize 0\n",
      "2019-04-03 22:03:13,894 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-04-03 22:03:13,894 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-04-03 22:03:13,899 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-04-03 22:03:13,903 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-04-03 22:03:13,913 : INFO : EPOCH 8 - PROGRESS: at 99.95% examples, 1119187 words/s, in_qsize 1, out_qsize 1\n",
      "2019-04-03 22:03:13,914 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-04-03 22:03:13,918 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-04-03 22:03:13,918 : INFO : EPOCH - 8 : training on 17408254 raw words (13499369 effective words) took 12.1s, 1119348 effective words/s\n",
      "2019-04-03 22:03:14,928 : INFO : EPOCH 9 - PROGRESS: at 6.86% examples, 1066360 words/s, in_qsize 11, out_qsize 0\n",
      "2019-04-03 22:03:15,930 : INFO : EPOCH 9 - PROGRESS: at 14.21% examples, 1085732 words/s, in_qsize 11, out_qsize 0\n",
      "2019-04-03 22:03:16,932 : INFO : EPOCH 9 - PROGRESS: at 23.13% examples, 1102918 words/s, in_qsize 11, out_qsize 0\n",
      "2019-04-03 22:03:17,940 : INFO : EPOCH 9 - PROGRESS: at 31.99% examples, 1107751 words/s, in_qsize 11, out_qsize 0\n",
      "2019-04-03 22:03:18,941 : INFO : EPOCH 9 - PROGRESS: at 40.84% examples, 1112243 words/s, in_qsize 11, out_qsize 0\n",
      "2019-04-03 22:03:19,942 : INFO : EPOCH 9 - PROGRESS: at 49.70% examples, 1115411 words/s, in_qsize 11, out_qsize 0\n",
      "2019-04-03 22:03:20,943 : INFO : EPOCH 9 - PROGRESS: at 58.48% examples, 1116485 words/s, in_qsize 11, out_qsize 0\n",
      "2019-04-03 22:03:21,950 : INFO : EPOCH 9 - PROGRESS: at 67.34% examples, 1117358 words/s, in_qsize 11, out_qsize 0\n",
      "2019-04-03 22:03:22,955 : INFO : EPOCH 9 - PROGRESS: at 76.18% examples, 1118341 words/s, in_qsize 11, out_qsize 0\n",
      "2019-04-03 22:03:23,963 : INFO : EPOCH 9 - PROGRESS: at 85.02% examples, 1118723 words/s, in_qsize 11, out_qsize 0\n",
      "2019-04-03 22:03:24,965 : INFO : EPOCH 9 - PROGRESS: at 92.52% examples, 1117495 words/s, in_qsize 11, out_qsize 0\n",
      "2019-04-03 22:03:25,969 : INFO : EPOCH 9 - PROGRESS: at 99.59% examples, 1115694 words/s, in_qsize 9, out_qsize 0\n",
      "2019-04-03 22:03:25,990 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-04-03 22:03:25,995 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-04-03 22:03:26,015 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-04-03 22:03:26,016 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-04-03 22:03:26,017 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-04-03 22:03:26,025 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-04-03 22:03:26,026 : INFO : EPOCH - 9 : training on 17408254 raw words (13499859 effective words) took 12.1s, 1115613 effective words/s\n",
      "2019-04-03 22:03:27,040 : INFO : EPOCH 10 - PROGRESS: at 6.91% examples, 1068673 words/s, in_qsize 11, out_qsize 0\n",
      "2019-04-03 22:03:28,045 : INFO : EPOCH 10 - PROGRESS: at 14.39% examples, 1092912 words/s, in_qsize 11, out_qsize 0\n",
      "2019-04-03 22:03:29,048 : INFO : EPOCH 10 - PROGRESS: at 23.25% examples, 1104799 words/s, in_qsize 11, out_qsize 0\n",
      "2019-04-03 22:03:30,054 : INFO : EPOCH 10 - PROGRESS: at 32.10% examples, 1109757 words/s, in_qsize 11, out_qsize 0\n",
      "2019-04-03 22:03:31,056 : INFO : EPOCH 10 - PROGRESS: at 40.97% examples, 1113571 words/s, in_qsize 11, out_qsize 0\n",
      "2019-04-03 22:03:32,057 : INFO : EPOCH 10 - PROGRESS: at 49.76% examples, 1115149 words/s, in_qsize 11, out_qsize 0\n",
      "2019-04-03 22:03:33,059 : INFO : EPOCH 10 - PROGRESS: at 58.55% examples, 1116088 words/s, in_qsize 11, out_qsize 0\n",
      "2019-04-03 22:03:34,064 : INFO : EPOCH 10 - PROGRESS: at 67.46% examples, 1118224 words/s, in_qsize 11, out_qsize 0\n",
      "2019-04-03 22:03:35,069 : INFO : EPOCH 10 - PROGRESS: at 76.30% examples, 1119006 words/s, in_qsize 12, out_qsize 0\n",
      "2019-04-03 22:03:36,073 : INFO : EPOCH 10 - PROGRESS: at 85.08% examples, 1119138 words/s, in_qsize 11, out_qsize 0\n",
      "2019-04-03 22:03:37,073 : INFO : EPOCH 10 - PROGRESS: at 92.52% examples, 1117406 words/s, in_qsize 11, out_qsize 0\n",
      "2019-04-03 22:03:38,078 : INFO : EPOCH 10 - PROGRESS: at 99.54% examples, 1114752 words/s, in_qsize 10, out_qsize 0\n",
      "2019-04-03 22:03:38,104 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-04-03 22:03:38,105 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-04-03 22:03:38,118 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-04-03 22:03:38,123 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-04-03 22:03:38,129 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-04-03 22:03:38,136 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-04-03 22:03:38,136 : INFO : EPOCH - 10 : training on 17408254 raw words (13498324 effective words) took 12.1s, 1115217 effective words/s\n",
      "2019-04-03 22:03:39,150 : INFO : EPOCH 11 - PROGRESS: at 6.91% examples, 1069455 words/s, in_qsize 11, out_qsize 0\n",
      "2019-04-03 22:03:40,157 : INFO : EPOCH 11 - PROGRESS: at 14.27% examples, 1084667 words/s, in_qsize 12, out_qsize 1\n",
      "2019-04-03 22:03:41,166 : INFO : EPOCH 11 - PROGRESS: at 23.13% examples, 1096998 words/s, in_qsize 11, out_qsize 0\n",
      "2019-04-03 22:03:42,168 : INFO : EPOCH 11 - PROGRESS: at 31.99% examples, 1105108 words/s, in_qsize 11, out_qsize 0\n",
      "2019-04-03 22:03:43,169 : INFO : EPOCH 11 - PROGRESS: at 40.30% examples, 1096375 words/s, in_qsize 11, out_qsize 0\n",
      "2019-04-03 22:03:44,175 : INFO : EPOCH 11 - PROGRESS: at 47.63% examples, 1068700 words/s, in_qsize 12, out_qsize 0\n",
      "2019-04-03 22:03:45,187 : INFO : EPOCH 11 - PROGRESS: at 54.98% examples, 1048399 words/s, in_qsize 11, out_qsize 0\n",
      "2019-04-03 22:03:46,206 : INFO : EPOCH 11 - PROGRESS: at 62.44% examples, 1034147 words/s, in_qsize 11, out_qsize 0\n",
      "2019-04-03 22:03:47,213 : INFO : EPOCH 11 - PROGRESS: at 69.88% examples, 1024370 words/s, in_qsize 11, out_qsize 0\n",
      "2019-04-03 22:03:48,214 : INFO : EPOCH 11 - PROGRESS: at 77.39% examples, 1017897 words/s, in_qsize 12, out_qsize 1\n",
      "2019-04-03 22:03:49,214 : INFO : EPOCH 11 - PROGRESS: at 84.66% examples, 1010025 words/s, in_qsize 11, out_qsize 0\n",
      "2019-04-03 22:03:50,228 : INFO : EPOCH 11 - PROGRESS: at 91.07% examples, 1002199 words/s, in_qsize 11, out_qsize 0\n",
      "2019-04-03 22:03:51,244 : INFO : EPOCH 11 - PROGRESS: at 96.96% examples, 994170 words/s, in_qsize 11, out_qsize 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-04-03 22:03:51,692 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-04-03 22:03:51,704 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-04-03 22:03:51,711 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-04-03 22:03:51,718 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-04-03 22:03:51,722 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-04-03 22:03:51,726 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-04-03 22:03:51,726 : INFO : EPOCH - 11 : training on 17408254 raw words (13497398 effective words) took 13.6s, 993706 effective words/s\n",
      "2019-04-03 22:03:52,735 : INFO : EPOCH 12 - PROGRESS: at 6.96% examples, 1082721 words/s, in_qsize 12, out_qsize 0\n",
      "2019-04-03 22:03:53,741 : INFO : EPOCH 12 - PROGRESS: at 14.33% examples, 1092503 words/s, in_qsize 11, out_qsize 0\n",
      "2019-04-03 22:03:54,747 : INFO : EPOCH 12 - PROGRESS: at 23.13% examples, 1100568 words/s, in_qsize 11, out_qsize 0\n",
      "2019-04-03 22:03:55,754 : INFO : EPOCH 12 - PROGRESS: at 31.99% examples, 1106364 words/s, in_qsize 11, out_qsize 0\n",
      "2019-04-03 22:03:56,756 : INFO : EPOCH 12 - PROGRESS: at 40.78% examples, 1109411 words/s, in_qsize 11, out_qsize 0\n",
      "2019-04-03 22:03:57,760 : INFO : EPOCH 12 - PROGRESS: at 49.70% examples, 1113569 words/s, in_qsize 11, out_qsize 0\n",
      "2019-04-03 22:03:58,765 : INFO : EPOCH 12 - PROGRESS: at 58.55% examples, 1115478 words/s, in_qsize 11, out_qsize 0\n",
      "2019-04-03 22:03:59,769 : INFO : EPOCH 12 - PROGRESS: at 67.40% examples, 1116878 words/s, in_qsize 11, out_qsize 0\n",
      "2019-04-03 22:04:00,771 : INFO : EPOCH 12 - PROGRESS: at 74.84% examples, 1098663 words/s, in_qsize 11, out_qsize 0\n",
      "2019-04-03 22:04:01,773 : INFO : EPOCH 12 - PROGRESS: at 82.12% examples, 1081622 words/s, in_qsize 11, out_qsize 0\n",
      "2019-04-03 22:04:02,782 : INFO : EPOCH 12 - PROGRESS: at 88.98% examples, 1067090 words/s, in_qsize 11, out_qsize 0\n",
      "2019-04-03 22:04:03,792 : INFO : EPOCH 12 - PROGRESS: at 94.91% examples, 1054025 words/s, in_qsize 11, out_qsize 0\n",
      "2019-04-03 22:04:04,614 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-04-03 22:04:04,637 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-04-03 22:04:04,640 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-04-03 22:04:04,641 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-04-03 22:04:04,646 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-04-03 22:04:04,648 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-04-03 22:04:04,648 : INFO : EPOCH - 12 : training on 17408254 raw words (13500064 effective words) took 12.9s, 1045373 effective words/s\n",
      "2019-04-03 22:04:05,672 : INFO : EPOCH 13 - PROGRESS: at 5.77% examples, 884642 words/s, in_qsize 11, out_qsize 0\n",
      "2019-04-03 22:04:06,686 : INFO : EPOCH 13 - PROGRESS: at 11.69% examples, 896399 words/s, in_qsize 11, out_qsize 0\n",
      "2019-04-03 22:04:07,691 : INFO : EPOCH 13 - PROGRESS: at 18.76% examples, 908615 words/s, in_qsize 11, out_qsize 0\n",
      "2019-04-03 22:04:08,699 : INFO : EPOCH 13 - PROGRESS: at 26.11% examples, 914078 words/s, in_qsize 11, out_qsize 0\n",
      "2019-04-03 22:04:09,708 : INFO : EPOCH 13 - PROGRESS: at 33.49% examples, 918707 words/s, in_qsize 11, out_qsize 0\n",
      "2019-04-03 22:04:10,720 : INFO : EPOCH 13 - PROGRESS: at 40.84% examples, 920001 words/s, in_qsize 11, out_qsize 0\n",
      "2019-04-03 22:04:11,722 : INFO : EPOCH 13 - PROGRESS: at 48.30% examples, 924384 words/s, in_qsize 12, out_qsize 0\n",
      "2019-04-03 22:04:12,724 : INFO : EPOCH 13 - PROGRESS: at 55.52% examples, 923902 words/s, in_qsize 11, out_qsize 0\n",
      "2019-04-03 22:04:13,726 : INFO : EPOCH 13 - PROGRESS: at 62.62% examples, 921887 words/s, in_qsize 12, out_qsize 0\n",
      "2019-04-03 22:04:14,730 : INFO : EPOCH 13 - PROGRESS: at 69.95% examples, 923037 words/s, in_qsize 11, out_qsize 0\n",
      "2019-04-03 22:04:15,738 : INFO : EPOCH 13 - PROGRESS: at 77.09% examples, 921642 words/s, in_qsize 11, out_qsize 0\n",
      "2019-04-03 22:04:16,743 : INFO : EPOCH 13 - PROGRESS: at 84.35% examples, 921884 words/s, in_qsize 11, out_qsize 0\n",
      "2019-04-03 22:04:17,761 : INFO : EPOCH 13 - PROGRESS: at 90.82% examples, 921207 words/s, in_qsize 11, out_qsize 0\n",
      "2019-04-03 22:04:18,768 : INFO : EPOCH 13 - PROGRESS: at 96.85% examples, 921854 words/s, in_qsize 11, out_qsize 0\n",
      "2019-04-03 22:04:19,257 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-04-03 22:04:19,271 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-04-03 22:04:19,296 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-04-03 22:04:19,300 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-04-03 22:04:19,302 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-04-03 22:04:19,304 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-04-03 22:04:19,305 : INFO : EPOCH - 13 : training on 17408254 raw words (13498332 effective words) took 14.6s, 921427 effective words/s\n",
      "2019-04-03 22:04:20,324 : INFO : EPOCH 14 - PROGRESS: at 5.67% examples, 882177 words/s, in_qsize 11, out_qsize 0\n",
      "2019-04-03 22:04:21,328 : INFO : EPOCH 14 - PROGRESS: at 11.74% examples, 911622 words/s, in_qsize 11, out_qsize 0\n",
      "2019-04-03 22:04:22,330 : INFO : EPOCH 14 - PROGRESS: at 20.41% examples, 986893 words/s, in_qsize 11, out_qsize 0\n",
      "2019-04-03 22:04:23,330 : INFO : EPOCH 14 - PROGRESS: at 29.56% examples, 1032684 words/s, in_qsize 11, out_qsize 0\n",
      "2019-04-03 22:04:24,338 : INFO : EPOCH 14 - PROGRESS: at 38.78% examples, 1059967 words/s, in_qsize 11, out_qsize 0\n",
      "2019-04-03 22:04:25,341 : INFO : EPOCH 14 - PROGRESS: at 47.94% examples, 1077596 words/s, in_qsize 11, out_qsize 0\n",
      "2019-04-03 22:04:26,344 : INFO : EPOCH 14 - PROGRESS: at 57.16% examples, 1091645 words/s, in_qsize 11, out_qsize 0\n",
      "2019-04-03 22:04:27,347 : INFO : EPOCH 14 - PROGRESS: at 66.31% examples, 1101041 words/s, in_qsize 11, out_qsize 0\n",
      "2019-04-03 22:04:28,352 : INFO : EPOCH 14 - PROGRESS: at 75.45% examples, 1108110 words/s, in_qsize 11, out_qsize 0\n",
      "2019-04-03 22:04:29,355 : INFO : EPOCH 14 - PROGRESS: at 84.60% examples, 1114032 words/s, in_qsize 11, out_qsize 0\n",
      "2019-04-03 22:04:30,357 : INFO : EPOCH 14 - PROGRESS: at 92.42% examples, 1116703 words/s, in_qsize 11, out_qsize 0\n",
      "2019-04-03 22:04:31,361 : INFO : EPOCH 14 - PROGRESS: at 99.75% examples, 1118185 words/s, in_qsize 5, out_qsize 1\n",
      "2019-04-03 22:04:31,363 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-04-03 22:04:31,365 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-04-03 22:04:31,367 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-04-03 22:04:31,372 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-04-03 22:04:31,388 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-04-03 22:04:31,391 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-04-03 22:04:31,392 : INFO : EPOCH - 14 : training on 17408254 raw words (13498566 effective words) took 12.1s, 1118522 effective words/s\n",
      "2019-04-03 22:04:32,404 : INFO : EPOCH 15 - PROGRESS: at 7.16% examples, 1111691 words/s, in_qsize 11, out_qsize 0\n",
      "2019-04-03 22:04:33,411 : INFO : EPOCH 15 - PROGRESS: at 14.93% examples, 1128718 words/s, in_qsize 11, out_qsize 0\n",
      "2019-04-03 22:04:34,419 : INFO : EPOCH 15 - PROGRESS: at 24.17% examples, 1142105 words/s, in_qsize 11, out_qsize 0\n",
      "2019-04-03 22:04:35,424 : INFO : EPOCH 15 - PROGRESS: at 33.19% examples, 1143896 words/s, in_qsize 11, out_qsize 0\n",
      "2019-04-03 22:04:36,427 : INFO : EPOCH 15 - PROGRESS: at 42.35% examples, 1148634 words/s, in_qsize 10, out_qsize 1\n",
      "2019-04-03 22:04:37,435 : INFO : EPOCH 15 - PROGRESS: at 51.52% examples, 1150521 words/s, in_qsize 11, out_qsize 0\n",
      "2019-04-03 22:04:38,445 : INFO : EPOCH 15 - PROGRESS: at 60.73% examples, 1152974 words/s, in_qsize 11, out_qsize 0\n",
      "2019-04-03 22:04:39,448 : INFO : EPOCH 15 - PROGRESS: at 69.89% examples, 1154616 words/s, in_qsize 11, out_qsize 0\n",
      "2019-04-03 22:04:40,455 : INFO : EPOCH 15 - PROGRESS: at 79.02% examples, 1155430 words/s, in_qsize 11, out_qsize 0\n",
      "2019-04-03 22:04:41,464 : INFO : EPOCH 15 - PROGRESS: at 87.93% examples, 1155132 words/s, in_qsize 11, out_qsize 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-04-03 22:04:42,476 : INFO : EPOCH 15 - PROGRESS: at 95.36% examples, 1153661 words/s, in_qsize 11, out_qsize 0\n",
      "2019-04-03 22:04:43,073 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-04-03 22:04:43,078 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-04-03 22:04:43,082 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-04-03 22:04:43,086 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-04-03 22:04:43,091 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-04-03 22:04:43,097 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-04-03 22:04:43,098 : INFO : EPOCH - 15 : training on 17408254 raw words (13498154 effective words) took 11.7s, 1153975 effective words/s\n",
      "2019-04-03 22:04:44,113 : INFO : EPOCH 16 - PROGRESS: at 7.21% examples, 1113349 words/s, in_qsize 11, out_qsize 0\n",
      "2019-04-03 22:04:45,115 : INFO : EPOCH 16 - PROGRESS: at 14.93% examples, 1128923 words/s, in_qsize 11, out_qsize 0\n",
      "2019-04-03 22:04:46,115 : INFO : EPOCH 16 - PROGRESS: at 24.04% examples, 1139923 words/s, in_qsize 11, out_qsize 0\n",
      "2019-04-03 22:04:47,117 : INFO : EPOCH 16 - PROGRESS: at 33.19% examples, 1147028 words/s, in_qsize 11, out_qsize 0\n",
      "2019-04-03 22:04:48,120 : INFO : EPOCH 16 - PROGRESS: at 42.35% examples, 1151043 words/s, in_qsize 11, out_qsize 0\n",
      "2019-04-03 22:04:49,121 : INFO : EPOCH 16 - PROGRESS: at 51.46% examples, 1152661 words/s, in_qsize 11, out_qsize 0\n",
      "2019-04-03 22:04:50,122 : INFO : EPOCH 16 - PROGRESS: at 60.61% examples, 1155131 words/s, in_qsize 11, out_qsize 0\n",
      "2019-04-03 22:04:51,127 : INFO : EPOCH 16 - PROGRESS: at 69.71% examples, 1155299 words/s, in_qsize 11, out_qsize 0\n",
      "2019-04-03 22:04:52,130 : INFO : EPOCH 16 - PROGRESS: at 78.72% examples, 1154747 words/s, in_qsize 11, out_qsize 0\n",
      "2019-04-03 22:04:53,132 : INFO : EPOCH 16 - PROGRESS: at 87.58% examples, 1153786 words/s, in_qsize 11, out_qsize 0\n",
      "2019-04-03 22:04:54,141 : INFO : EPOCH 16 - PROGRESS: at 94.66% examples, 1147849 words/s, in_qsize 11, out_qsize 0\n",
      "2019-04-03 22:04:54,865 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-04-03 22:04:54,872 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-04-03 22:04:54,875 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-04-03 22:04:54,880 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-04-03 22:04:54,892 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-04-03 22:04:54,897 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-04-03 22:04:54,898 : INFO : EPOCH - 16 : training on 17408254 raw words (13496995 effective words) took 11.8s, 1144494 effective words/s\n",
      "2019-04-03 22:04:55,908 : INFO : EPOCH 17 - PROGRESS: at 6.91% examples, 1072264 words/s, in_qsize 11, out_qsize 0\n",
      "2019-04-03 22:04:56,912 : INFO : EPOCH 17 - PROGRESS: at 14.27% examples, 1088263 words/s, in_qsize 11, out_qsize 0\n",
      "2019-04-03 22:04:57,915 : INFO : EPOCH 17 - PROGRESS: at 23.07% examples, 1098730 words/s, in_qsize 11, out_qsize 0\n",
      "2019-04-03 22:04:58,915 : INFO : EPOCH 17 - PROGRESS: at 31.92% examples, 1106910 words/s, in_qsize 11, out_qsize 0\n",
      "2019-04-03 22:04:59,916 : INFO : EPOCH 17 - PROGRESS: at 40.78% examples, 1111710 words/s, in_qsize 11, out_qsize 0\n",
      "2019-04-03 22:05:00,926 : INFO : EPOCH 17 - PROGRESS: at 49.58% examples, 1111774 words/s, in_qsize 11, out_qsize 0\n",
      "2019-04-03 22:05:01,929 : INFO : EPOCH 17 - PROGRESS: at 58.42% examples, 1114014 words/s, in_qsize 11, out_qsize 0\n",
      "2019-04-03 22:05:02,939 : INFO : EPOCH 17 - PROGRESS: at 67.28% examples, 1114817 words/s, in_qsize 11, out_qsize 0\n",
      "2019-04-03 22:05:03,946 : INFO : EPOCH 17 - PROGRESS: at 76.12% examples, 1115740 words/s, in_qsize 11, out_qsize 0\n",
      "2019-04-03 22:05:04,952 : INFO : EPOCH 17 - PROGRESS: at 84.90% examples, 1115922 words/s, in_qsize 11, out_qsize 0\n",
      "2019-04-03 22:05:05,957 : INFO : EPOCH 17 - PROGRESS: at 92.42% examples, 1114714 words/s, in_qsize 11, out_qsize 0\n",
      "2019-04-03 22:05:06,957 : INFO : EPOCH 17 - PROGRESS: at 99.49% examples, 1113406 words/s, in_qsize 11, out_qsize 0\n",
      "2019-04-03 22:05:06,997 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-04-03 22:05:07,003 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-04-03 22:05:07,011 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-04-03 22:05:07,018 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-04-03 22:05:07,023 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-04-03 22:05:07,029 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-04-03 22:05:07,029 : INFO : EPOCH - 17 : training on 17408254 raw words (13497248 effective words) took 12.1s, 1113220 effective words/s\n",
      "2019-04-03 22:05:08,043 : INFO : EPOCH 18 - PROGRESS: at 6.91% examples, 1070011 words/s, in_qsize 11, out_qsize 0\n",
      "2019-04-03 22:05:09,050 : INFO : EPOCH 18 - PROGRESS: at 14.27% examples, 1085127 words/s, in_qsize 11, out_qsize 0\n",
      "2019-04-03 22:05:10,051 : INFO : EPOCH 18 - PROGRESS: at 23.13% examples, 1100194 words/s, in_qsize 11, out_qsize 0\n",
      "2019-04-03 22:05:11,053 : INFO : EPOCH 18 - PROGRESS: at 31.86% examples, 1103546 words/s, in_qsize 11, out_qsize 0\n",
      "2019-04-03 22:05:12,062 : INFO : EPOCH 18 - PROGRESS: at 40.72% examples, 1107173 words/s, in_qsize 11, out_qsize 0\n",
      "2019-04-03 22:05:13,065 : INFO : EPOCH 18 - PROGRESS: at 49.51% examples, 1109340 words/s, in_qsize 11, out_qsize 0\n",
      "2019-04-03 22:05:14,067 : INFO : EPOCH 18 - PROGRESS: at 58.36% examples, 1112226 words/s, in_qsize 11, out_qsize 0\n",
      "2019-04-03 22:05:15,078 : INFO : EPOCH 18 - PROGRESS: at 67.22% examples, 1113165 words/s, in_qsize 11, out_qsize 0\n",
      "2019-04-03 22:05:16,079 : INFO : EPOCH 18 - PROGRESS: at 76.06% examples, 1114865 words/s, in_qsize 11, out_qsize 0\n",
      "2019-04-03 22:05:17,088 : INFO : EPOCH 18 - PROGRESS: at 84.90% examples, 1115622 words/s, in_qsize 11, out_qsize 0\n",
      "2019-04-03 22:05:18,093 : INFO : EPOCH 18 - PROGRESS: at 92.42% examples, 1114401 words/s, in_qsize 12, out_qsize 0\n",
      "2019-04-03 22:05:19,094 : INFO : EPOCH 18 - PROGRESS: at 99.39% examples, 1111723 words/s, in_qsize 11, out_qsize 0\n",
      "2019-04-03 22:05:19,142 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-04-03 22:05:19,157 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-04-03 22:05:19,158 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-04-03 22:05:19,161 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-04-03 22:05:19,169 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-04-03 22:05:19,172 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-04-03 22:05:19,173 : INFO : EPOCH - 18 : training on 17408254 raw words (13498340 effective words) took 12.1s, 1112242 effective words/s\n",
      "2019-04-03 22:05:20,182 : INFO : EPOCH 19 - PROGRESS: at 6.86% examples, 1065594 words/s, in_qsize 11, out_qsize 0\n",
      "2019-04-03 22:05:21,183 : INFO : EPOCH 19 - PROGRESS: at 14.21% examples, 1086052 words/s, in_qsize 11, out_qsize 0\n",
      "2019-04-03 22:05:22,186 : INFO : EPOCH 19 - PROGRESS: at 23.07% examples, 1100200 words/s, in_qsize 11, out_qsize 0\n",
      "2019-04-03 22:05:23,189 : INFO : EPOCH 19 - PROGRESS: at 31.99% examples, 1109171 words/s, in_qsize 12, out_qsize 0\n",
      "2019-04-03 22:05:24,192 : INFO : EPOCH 19 - PROGRESS: at 40.78% examples, 1111362 words/s, in_qsize 11, out_qsize 0\n",
      "2019-04-03 22:05:25,197 : INFO : EPOCH 19 - PROGRESS: at 49.64% examples, 1113835 words/s, in_qsize 11, out_qsize 0\n",
      "2019-04-03 22:05:26,201 : INFO : EPOCH 19 - PROGRESS: at 58.36% examples, 1113554 words/s, in_qsize 11, out_qsize 0\n",
      "2019-04-03 22:05:27,208 : INFO : EPOCH 19 - PROGRESS: at 67.22% examples, 1114839 words/s, in_qsize 11, out_qsize 0\n",
      "2019-04-03 22:05:28,211 : INFO : EPOCH 19 - PROGRESS: at 76.06% examples, 1116315 words/s, in_qsize 11, out_qsize 0\n",
      "2019-04-03 22:05:29,221 : INFO : EPOCH 19 - PROGRESS: at 84.96% examples, 1117475 words/s, in_qsize 11, out_qsize 0\n",
      "2019-04-03 22:05:30,229 : INFO : EPOCH 19 - PROGRESS: at 92.52% examples, 1116624 words/s, in_qsize 11, out_qsize 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-04-03 22:05:31,232 : INFO : EPOCH 19 - PROGRESS: at 99.64% examples, 1115508 words/s, in_qsize 8, out_qsize 0\n",
      "2019-04-03 22:05:31,259 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-04-03 22:05:31,261 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-04-03 22:05:31,272 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-04-03 22:05:31,273 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-04-03 22:05:31,277 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-04-03 22:05:31,292 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-04-03 22:05:31,293 : INFO : EPOCH - 19 : training on 17408254 raw words (13500044 effective words) took 12.1s, 1114477 effective words/s\n",
      "2019-04-03 22:05:32,303 : INFO : EPOCH 20 - PROGRESS: at 6.91% examples, 1074322 words/s, in_qsize 11, out_qsize 0\n",
      "2019-04-03 22:05:33,309 : INFO : EPOCH 20 - PROGRESS: at 14.27% examples, 1087708 words/s, in_qsize 11, out_qsize 0\n",
      "2019-04-03 22:05:34,312 : INFO : EPOCH 20 - PROGRESS: at 23.19% examples, 1103765 words/s, in_qsize 11, out_qsize 0\n",
      "2019-04-03 22:05:35,313 : INFO : EPOCH 20 - PROGRESS: at 31.92% examples, 1106534 words/s, in_qsize 11, out_qsize 0\n",
      "2019-04-03 22:05:36,317 : INFO : EPOCH 20 - PROGRESS: at 40.78% examples, 1110749 words/s, in_qsize 12, out_qsize 0\n",
      "2019-04-03 22:05:37,324 : INFO : EPOCH 20 - PROGRESS: at 49.64% examples, 1112991 words/s, in_qsize 11, out_qsize 0\n",
      "2019-04-03 22:05:38,332 : INFO : EPOCH 20 - PROGRESS: at 58.55% examples, 1115526 words/s, in_qsize 11, out_qsize 0\n",
      "2019-04-03 22:05:39,338 : INFO : EPOCH 20 - PROGRESS: at 67.40% examples, 1116632 words/s, in_qsize 11, out_qsize 0\n",
      "2019-04-03 22:05:40,338 : INFO : EPOCH 20 - PROGRESS: at 76.18% examples, 1117324 words/s, in_qsize 11, out_qsize 0\n",
      "2019-04-03 22:05:41,342 : INFO : EPOCH 20 - PROGRESS: at 85.08% examples, 1119049 words/s, in_qsize 11, out_qsize 0\n",
      "2019-04-03 22:05:42,344 : INFO : EPOCH 20 - PROGRESS: at 92.52% examples, 1117164 words/s, in_qsize 11, out_qsize 0\n",
      "2019-04-03 22:05:43,349 : INFO : EPOCH 20 - PROGRESS: at 99.64% examples, 1115928 words/s, in_qsize 8, out_qsize 0\n",
      "2019-04-03 22:05:43,368 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-04-03 22:05:43,371 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-04-03 22:05:43,376 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-04-03 22:05:43,390 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-04-03 22:05:43,397 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-04-03 22:05:43,399 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-04-03 22:05:43,399 : INFO : EPOCH - 20 : training on 17408254 raw words (13500802 effective words) took 12.1s, 1115871 effective words/s\n",
      "2019-04-03 22:05:43,399 : INFO : training on a 348165080 raw words (269972622 effective words) took 251.3s, 1074103 effective words/s\n"
     ]
    }
   ],
   "source": [
    "# sg=1 means Skip-gram \n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)\n",
    "w2vmodel = word2vec.Word2Vec(texts, size=200, sg=1, min_count=1, window=3, workers=6, iter=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-04-03 22:07:11,370 : INFO : saving Word2Vec object under w2vmodel.model, separately None\n",
      "2019-04-03 22:07:11,371 : INFO : storing np array 'vectors' to w2vmodel.model.wv.vectors.npy\n",
      "2019-04-03 22:07:11,548 : INFO : not storing attribute vectors_norm\n",
      "2019-04-03 22:07:11,552 : INFO : storing np array 'syn1neg' to w2vmodel.model.trainables.syn1neg.npy\n",
      "2019-04-03 22:07:11,713 : INFO : not storing attribute cum_table\n",
      "2019-04-03 22:07:11,902 : INFO : saved w2vmodel.model\n"
     ]
    }
   ],
   "source": [
    "w2vmodel.save(\"w2vmodel.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-04-03 22:07:13,715 : INFO : loading Word2Vec object from w2vmodel.model\n",
      "2019-04-03 22:07:13,821 : INFO : loading wv recursively from w2vmodel.model.wv.* with mmap=None\n",
      "2019-04-03 22:07:13,822 : INFO : loading vectors from w2vmodel.model.wv.vectors.npy with mmap=None\n",
      "2019-04-03 22:07:13,854 : INFO : setting ignored attribute vectors_norm to None\n",
      "2019-04-03 22:07:13,854 : INFO : loading vocabulary recursively from w2vmodel.model.vocabulary.* with mmap=None\n",
      "2019-04-03 22:07:13,855 : INFO : loading trainables recursively from w2vmodel.model.trainables.* with mmap=None\n",
      "2019-04-03 22:07:13,855 : INFO : loading syn1neg from w2vmodel.model.trainables.syn1neg.npy with mmap=None\n",
      "2019-04-03 22:07:13,886 : INFO : setting ignored attribute cum_table to None\n",
      "2019-04-03 22:07:13,887 : INFO : loaded w2vmodel.model\n"
     ]
    }
   ],
   "source": [
    "w2vmodel = word2vec.Word2Vec.load(\"w2vmodel.model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "隨便測試一個字看看！"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.2597136 ,  0.0680491 ,  0.14870939, -0.06785405,  0.01889782,\n",
       "       -0.18520711, -0.1885602 , -0.0995933 ,  0.35392967,  0.1888192 ,\n",
       "       -0.25261167,  0.11654913, -0.44418007,  0.2067864 , -0.15940247,\n",
       "       -0.14691448, -0.05473197,  0.39358056,  0.01704257,  0.12057644,\n",
       "       -0.3107193 ,  0.42072743, -0.01560979, -0.41902515,  0.73674464,\n",
       "        0.37681928,  0.27171925,  0.14049773,  0.23618628, -0.2943771 ,\n",
       "       -0.08489822,  0.4050786 , -0.2586974 , -0.11106346,  0.29834905,\n",
       "        0.7025178 ,  0.00437329, -0.4504733 , -0.45381746,  0.03983081,\n",
       "       -0.19527617, -0.26875544,  0.2207269 , -0.07695176, -0.02419234,\n",
       "       -0.00083169, -0.00693199, -0.07137527,  0.28264153, -0.09566917,\n",
       "        0.3498552 ,  0.04825199,  0.16344097, -0.1640132 , -0.3556715 ,\n",
       "        0.24367857,  0.7240531 , -0.47524574,  0.28263304, -0.30293864,\n",
       "       -0.4570374 , -0.13742852, -0.1785007 ,  0.10404795,  0.03954203,\n",
       "        0.11146531, -0.02262113, -0.15684307, -0.5676298 ,  0.04986193,\n",
       "        0.34197327, -0.03955447,  0.20726262, -0.5913954 ,  0.23930453,\n",
       "        0.13467532,  0.0733848 ,  0.10116234,  0.31979078,  0.27753457,\n",
       "        0.08625503,  0.33921835, -0.04953134, -0.16447407, -0.27528712,\n",
       "       -0.14196296,  0.06451045,  0.54210067,  0.3509371 , -0.10259928,\n",
       "        0.25438613,  0.23469546,  0.23170558, -0.2475894 ,  0.11323483,\n",
       "        0.29477894,  0.19017631, -0.49159548, -0.12422414,  0.02494697,\n",
       "        0.23526229, -0.54337215, -0.30660826,  0.3072639 , -0.13596898,\n",
       "       -0.5807439 , -0.33371347,  0.10605635,  0.23572578, -0.05740747,\n",
       "        0.03384475,  0.15015696,  0.17124653, -0.09223745, -0.11402689,\n",
       "        0.06098657,  0.25696295,  0.20664887,  0.25193506, -0.31718197,\n",
       "        0.15477447,  0.57604975,  0.6027699 , -0.07276523, -0.38284686,\n",
       "       -0.08858196,  0.0837115 , -0.35354096, -0.02221663,  0.06321048,\n",
       "        0.09793072,  0.383323  ,  0.4671122 , -0.05436807, -0.41073132,\n",
       "       -0.23809904, -0.43494457, -0.04412814,  0.03151992,  0.43255016,\n",
       "       -0.3262592 , -0.12654468,  0.56288314,  0.19817044, -0.5698238 ,\n",
       "       -0.26863226, -0.1611733 ,  0.43148765,  0.377581  , -0.10575581,\n",
       "       -0.32357556, -0.23711358,  0.07492305, -0.03477176, -0.05370041,\n",
       "       -0.00845689,  0.22642723, -0.18285114, -0.2327736 , -0.28808644,\n",
       "        0.6737038 ,  0.0206639 , -0.656688  , -0.190423  , -0.20219757,\n",
       "       -0.15758632, -0.3134584 ,  0.8110647 , -0.20034064, -0.35791442,\n",
       "       -0.08898036,  0.05153929, -0.15398827,  0.10646459, -0.2254098 ,\n",
       "        0.06572313, -0.18216719,  0.07423092,  0.2122751 ,  0.13488846,\n",
       "       -0.13033353,  0.2607309 , -0.10388308,  0.590863  ,  0.58998096,\n",
       "       -0.24440946,  0.04852055,  0.13971648,  0.25255874,  0.07802321,\n",
       "       -0.35198992, -0.4129694 ,  0.16599473,  0.01970228, -0.50249946,\n",
       "        0.25469902,  0.17706989, -0.16562967,  0.09756405, -0.18051594],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2vmodel.wv[\"computer\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "117286"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(w2vmodel.wv.vocab.items())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "這是weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.03790323, -0.25120223, -0.06700747, ..., -0.12902237,\n",
       "         0.14676812, -0.40879408],\n",
       "       [-0.21863802, -0.15415996,  0.02521611, ...,  0.12911823,\n",
       "         0.20452441, -0.2958011 ],\n",
       "       [ 0.12032862, -0.17554872,  0.04350717, ..., -0.01508772,\n",
       "         0.01840604, -0.17322086],\n",
       "       ...,\n",
       "       [-0.00238501,  0.05989103,  0.11711463, ..., -0.07439116,\n",
       "         0.17107767, -0.1232437 ],\n",
       "       [-0.12950729,  0.03237965,  0.14300607, ..., -0.04196416,\n",
       "         0.2047708 , -0.14363886],\n",
       "       [-0.08707895, -0.11553323,  0.10134102, ...,  0.00723493,\n",
       "         0.2708728 , -0.13376625]], dtype=float32)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2vmodel.wv.vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(117286, 200)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size, embedding_size = w2vmodel.wv.vectors.shape\n",
    "w2vmodel.wv.vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wordtoidx(word):\n",
    "    if word not in w2vmodel.wv.vocab:\n",
    "        return 0\n",
    "    else: \n",
    "        return w2vmodel.wv.vocab[word].index\n",
    "def idxtoword(idx):\n",
    "    return w2vmodel.wv.index2word[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2idx = {\"_PAD\": 0} \n",
    "\n",
    "# 多一位PADDING = 0\n",
    "embeddings_matrix = np.zeros((vocab_size + 1, embedding_size))\n",
    "for i in range(vocab_size):\n",
    "    word = idxtoword(i)\n",
    "    word2idx[word] = i + 1\n",
    "    embeddings_matrix[i + 1] = w2vmodel.wv.vectors[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [-0.03790323, -0.25120223, -0.06700747, ..., -0.12902237,\n",
       "         0.14676812, -0.40879408],\n",
       "       [-0.21863802, -0.15415996,  0.02521611, ...,  0.12911823,\n",
       "         0.20452441, -0.2958011 ],\n",
       "       ...,\n",
       "       [-0.00238501,  0.05989103,  0.11711463, ..., -0.07439116,\n",
       "         0.17107767, -0.1232437 ],\n",
       "       [-0.12950729,  0.03237965,  0.14300607, ..., -0.04196416,\n",
       "         0.2047708 , -0.14363886],\n",
       "       [-0.08707895, -0.11553323,  0.10134102, ...,  0.00723493,\n",
       "         0.2708728 , -0.13376625]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "跟原本的對照一下！"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.03790323, -0.25120223, -0.06700747, ..., -0.12902237,\n",
       "         0.14676812, -0.40879408],\n",
       "       [-0.21863802, -0.15415996,  0.02521611, ...,  0.12911823,\n",
       "         0.20452441, -0.2958011 ],\n",
       "       [ 0.12032862, -0.17554872,  0.04350717, ..., -0.01508772,\n",
       "         0.01840604, -0.17322086],\n",
       "       ...,\n",
       "       [-0.00238501,  0.05989103,  0.11711463, ..., -0.07439116,\n",
       "         0.17107767, -0.1232437 ],\n",
       "       [-0.12950729,  0.03237965,  0.14300607, ..., -0.04196416,\n",
       "         0.2047708 , -0.14363886],\n",
       "       [-0.08707895, -0.11553323,  0.10134102, ...,  0.00723493,\n",
       "         0.2708728 , -0.13376625]], dtype=float32)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2vmodel.wv.vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(117287, 200)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings_matrix.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "建立ＬＳＴＭ模型型型！！！"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, None, 200)         23457400  \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, None, 200)         320800    \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 200)               320800    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 201       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 24,099,201\n",
      "Trainable params: 641,801\n",
      "Non-trainable params: 23,457,400\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "lstmmodel = Sequential()\n",
    "lstmmodel.add(Embedding(input_dim=vocab_size + 1, output_dim=embedding_size, \\\n",
    "                   weights=[embeddings_matrix], trainable=False))\n",
    "lstmmodel.add(LSTM(units=embedding_size, return_sequences=True, dropout=0.4))\n",
    "lstmmodel.add(LSTM(units=embedding_size, dropout=0.4))\n",
    "lstmmodel.add(Dense(units=1)) # output 只有1個neuron，正評或負評\n",
    "lstmmodel.add(Activation(\"sigmoid\"))\n",
    "\n",
    "lstmmodel.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"acc\"])\n",
    "\n",
    "lstmmodel.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "準備訓練資料集！前200000行為訓練資料集，將每個字轉到對應的id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "37"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainlist = texts[:200000]\n",
    "max_length = max([len(x) for x in trainlist])\n",
    "max_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 0, ..., 0, 1, 0])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target = np.array(train[\"target\"])\n",
    "target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = np.zeros([len(trainlist), max_length], dtype=np.int32)\n",
    "train_y = np.zeros([len(trainlist)], dtype=np.int32)\n",
    "for i, sentence in enumerate(trainlist):\n",
    "    for t, word in enumerate(sentence):\n",
    "        train_x[i, t] = wordtoidx(word)\n",
    "        train_y[i] = target[i]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "看一下第一行！"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'are wtf  awww thanks'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordlist[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 36, 752, 411,  76,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0], dtype=int32)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "真正要開始訓練了！！！！"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping = EarlyStopping(monitor=\"val_acc\", patience=5, verbose=1, mode=\"max\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 180000 samples, validate on 20000 samples\n",
      "Epoch 1/40\n",
      "180000/180000 [==============================] - 22s 123us/step - loss: 0.6480 - acc: 0.6184 - val_loss: 0.5777 - val_acc: 0.6963\n",
      "Epoch 2/40\n",
      "180000/180000 [==============================] - 21s 118us/step - loss: 0.5586 - acc: 0.7099 - val_loss: 0.5272 - val_acc: 0.7446\n",
      "Epoch 3/40\n",
      "180000/180000 [==============================] - 21s 118us/step - loss: 0.5242 - acc: 0.7378 - val_loss: 0.5002 - val_acc: 0.7573\n",
      "Epoch 4/40\n",
      "180000/180000 [==============================] - 21s 118us/step - loss: 0.5075 - acc: 0.7506 - val_loss: 0.4820 - val_acc: 0.7692\n",
      "Epoch 5/40\n",
      "180000/180000 [==============================] - 21s 118us/step - loss: 0.4945 - acc: 0.7597 - val_loss: 0.5074 - val_acc: 0.7438\n",
      "Epoch 6/40\n",
      "180000/180000 [==============================] - 21s 118us/step - loss: 0.4827 - acc: 0.7679 - val_loss: 0.4677 - val_acc: 0.7779\n",
      "Epoch 7/40\n",
      "180000/180000 [==============================] - 21s 118us/step - loss: 0.4758 - acc: 0.7715 - val_loss: 0.4649 - val_acc: 0.7807\n",
      "Epoch 8/40\n",
      "180000/180000 [==============================] - 21s 118us/step - loss: 0.4671 - acc: 0.7780 - val_loss: 0.4584 - val_acc: 0.7838\n",
      "Epoch 9/40\n",
      "180000/180000 [==============================] - 21s 118us/step - loss: 0.4621 - acc: 0.7810 - val_loss: 0.4574 - val_acc: 0.7860\n",
      "Epoch 10/40\n",
      "180000/180000 [==============================] - 22s 122us/step - loss: 0.4553 - acc: 0.7844 - val_loss: 0.4576 - val_acc: 0.7872\n",
      "Epoch 11/40\n",
      "180000/180000 [==============================] - 23s 126us/step - loss: 0.4490 - acc: 0.7884 - val_loss: 0.4560 - val_acc: 0.7866\n",
      "Epoch 12/40\n",
      "180000/180000 [==============================] - 21s 119us/step - loss: 0.4441 - acc: 0.7915 - val_loss: 0.4471 - val_acc: 0.7913\n",
      "Epoch 13/40\n",
      "180000/180000 [==============================] - 21s 119us/step - loss: 0.4383 - acc: 0.7948 - val_loss: 0.4424 - val_acc: 0.7923\n",
      "Epoch 14/40\n",
      "180000/180000 [==============================] - 22s 120us/step - loss: 0.4340 - acc: 0.7979 - val_loss: 0.4459 - val_acc: 0.7926\n",
      "Epoch 15/40\n",
      "180000/180000 [==============================] - 21s 119us/step - loss: 0.4301 - acc: 0.8006 - val_loss: 0.4411 - val_acc: 0.7947\n",
      "Epoch 16/40\n",
      "180000/180000 [==============================] - 21s 119us/step - loss: 0.4262 - acc: 0.8021 - val_loss: 0.4441 - val_acc: 0.7962\n",
      "Epoch 17/40\n",
      "180000/180000 [==============================] - 21s 119us/step - loss: 0.4228 - acc: 0.8037 - val_loss: 0.4357 - val_acc: 0.7979\n",
      "Epoch 18/40\n",
      "180000/180000 [==============================] - 21s 119us/step - loss: 0.4181 - acc: 0.8080 - val_loss: 0.4409 - val_acc: 0.7984\n",
      "Epoch 19/40\n",
      "180000/180000 [==============================] - 21s 119us/step - loss: 0.4143 - acc: 0.8083 - val_loss: 0.4362 - val_acc: 0.7965\n",
      "Epoch 20/40\n",
      "180000/180000 [==============================] - 21s 119us/step - loss: 0.4113 - acc: 0.8104 - val_loss: 0.4386 - val_acc: 0.8012\n",
      "Epoch 21/40\n",
      "180000/180000 [==============================] - 21s 119us/step - loss: 0.4083 - acc: 0.8122 - val_loss: 0.4333 - val_acc: 0.8006\n",
      "Epoch 22/40\n",
      "180000/180000 [==============================] - 21s 119us/step - loss: 0.4062 - acc: 0.8134 - val_loss: 0.4362 - val_acc: 0.8008\n",
      "Epoch 23/40\n",
      "180000/180000 [==============================] - 21s 119us/step - loss: 0.4001 - acc: 0.8168 - val_loss: 0.4449 - val_acc: 0.7891\n",
      "Epoch 24/40\n",
      "180000/180000 [==============================] - 21s 119us/step - loss: 0.4009 - acc: 0.8161 - val_loss: 0.4466 - val_acc: 0.7982\n",
      "Epoch 25/40\n",
      "180000/180000 [==============================] - 21s 119us/step - loss: 0.3969 - acc: 0.8193 - val_loss: 0.4396 - val_acc: 0.7982\n",
      "Epoch 00025: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fa90e072080>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstmmodel.fit(train_x, train_y, batch_size=500, epochs=40, verbose=1, validation_split=0.1, shuffle=True, \\\n",
    "             callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstmmodel.save(\"lstmmodel.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "載入模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tensorflow==1.12.0<br>\n",
    "keras==2.2.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstmmodel = load_model(\"lstmmodel.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "載入測試資料"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "39"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testlist = texts[-200000:]\n",
    "testmax_length = max([len(x) for x in testlist])\n",
    "testmax_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_x = np.zeros([len(testlist), testmax_length], dtype=np.int32)\n",
    "\n",
    "for i, sentence in enumerate(testlist):\n",
    "    for t, word in enumerate(sentence):\n",
    "        test_x[i, t] = wordtoidx(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_x = test_x[:,:max_length]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, None, 200)         23457400  \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, None, 200)         320800    \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 200)               320800    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 201       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 24,099,201\n",
      "Trainable params: 641,801\n",
      "Non-trainable params: 23,457,400\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "lstmmodel.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200000/200000 [==============================] - 9s 44us/step\n"
     ]
    }
   ],
   "source": [
    "predclass = lstmmodel.predict(test_x, batch_size=500, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.02000418],\n",
       "       [0.05712306],\n",
       "       [0.05215343],\n",
       "       ...,\n",
       "       [0.62821865],\n",
       "       [0.06688549],\n",
       "       [0.06750049]], dtype=float32)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predclass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([94935])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(predclass >= 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  label\n",
       "0   0      0\n",
       "1   1      0\n",
       "2   2      0\n",
       "3   3      0\n",
       "4   4      0"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submit = pd.read_csv(path + \"sampleSubmission.csv\")\n",
    "submit.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit[\"label\"] = predclass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.020004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.057123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.052153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.492487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.220749</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id     label\n",
       "0   0  0.020004\n",
       "1   1  0.057123\n",
       "2   2  0.052153\n",
       "3   3  0.492487\n",
       "4   4  0.220749"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submit.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  label\n",
       "0   0      0\n",
       "1   1      0\n",
       "2   2      0\n",
       "3   3      0\n",
       "4   4      0"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submit[\"label\"] = submit[\"label\"].apply(lambda x: 1 if x >= 0.5 else 0)\n",
    "submit.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "94935"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(submit[\"label\"] == 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit.to_csv(\"newgpu_submit4.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
